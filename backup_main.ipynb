{"cells":[{"cell_type":"markdown","metadata":{"id":"vobP7ahXP1EG"},"source":["# Graph-Learning-Based Recommender System on MovieLens\n","\n","### Group 9\n","\n","- AGARWAL, Sahil\n","- WEI, Yuanjing\n","- ZHANG, Yujun yzhanglo@connect.ust.hk\n","\n","Group project of COMP4222@HKUST in 2022 Fall."]},{"cell_type":"markdown","metadata":{"id":"QpTqYz7qYJbP"},"source":["# 1 Environment Configuration"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":603},"executionInfo":{"elapsed":30299,"status":"error","timestamp":1667642237984,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"MXxR7IpwI83o","outputId":"9933f848-12fa-442f-afe4-0d95a20a464e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[WinError 3] The system cannot find the path specified: \"'/data/yzhanglo/4222project'\"\n","c:\\Users\\sheng\\Documents\\GitHub\\4222project\n"," Volume in drive C is Windows\n"," Volume Serial Number is 9000-C8F8\n","\n"," Directory of c:\\Users\\sheng\\Documents\\GitHub\\4222project\n","\n","11/20/2022  12:02 AM    <DIR>          .\n","11/20/2022  12:02 AM    <DIR>          ..\n","11/05/2022  06:40 PM             3,246 .gitignore\n","11/20/2022  12:47 AM            46,762 backup_main.ipynb\n","11/05/2022  06:46 PM    <DIR>          comp4222\n","11/10/2022  10:01 PM    <DIR>          KGAT_folder\n","11/05/2022  06:40 PM             1,082 LICENSE\n","11/09/2022  11:43 PM    <DIR>          LightGCN\n","11/05/2022  06:40 PM               954 lightgcn.yaml\n","11/20/2022  12:04 AM            62,245 main.ipynb\n","11/10/2022  04:55 PM    <DIR>          ml-100k\n","11/05/2022  06:51 PM    <DIR>          ml-latest-small\n","11/10/2022  09:54 PM            44,786 movielens.ipynb\n","11/10/2022  07:02 PM         4,924,029 movielens.zip\n","11/20/2022  12:47 AM    <DIR>          recommenders\n","11/20/2022  12:02 AM               891 requirements.txt\n","               8 File(s)      5,083,995 bytes\n","               8 Dir(s)  61,460,910,080 bytes free\n"]}],"source":["# change the path in the following\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd '/content/drive/MyDrive/4222Group9'\n","except:\n","    %cd '/data/yzhanglo/4222project'\n","\n","import comp4222\n","import recommenders\n","%pwd\n","%ls"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1667642237987,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"7RuvfqktV-jm"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","#import tensorflow as tf\n","import torch\n","from tensorboardX import SummaryWriter\n","\n","# easier to print by putting variable as a single line\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","# make matplotlib figures appear inline in the notebook rather than in a new window.\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# Add some convenience functions to Pandas DataFrame.\n","pd.options.display.max_rows = 10\n","pd.options.display.float_format = '{:.2f}'.format\n","def mask(df, key, function):\n","  \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n","  return df[function(df[key])]\n","\n","def flatten_cols(df):\n","  df.columns = [' '.join(col).strip() for col in df.columns.values]\n","  return df\n","\n","pd.DataFrame.mask = mask\n","pd.DataFrame.flatten_cols = flatten_cols\n","\n","# http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1667642237988,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"zLFdbrlyOWiT"},"outputs":[{"name":"stdout","output_type":"stream","text":["hahaha\n"]}],"source":["# Testing the module functionality\n","from comp4222 import b\n","import recommenders\n","comp4222.b.ok()"]},{"cell_type":"markdown","metadata":{"id":"dkgjzCmnWXUw"},"source":["# 2 MovieLens\n"]},{"cell_type":"markdown","metadata":{"id":"Mq_PrL0LZrGa"},"source":["We're using ml-latest-small from MovieLens. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018. The readme.md is avaliable [here](https://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)."]},{"cell_type":"markdown","metadata":{"id":"g_XRmlt-yMUu"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1667642237989,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"Vt7THxaKWZDv"},"outputs":[{"ename":"URLError","evalue":"<urlopen error [Errno 11001] getaddrinfo failed>","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1254\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         self.sock = self._create_connection(\n\u001b[0m\u001b[0;32m    922\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20048/1548680868.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murlretrieve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"https://files.grouplens.org/datasets/movielens/{dataset_name}.zip\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"movielens.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"movielens.zip\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1352\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"]}],"source":["# Download MovieLens data.\n","dataset_name = \"ml-latest-small\"\n","from urllib.request import urlretrieve\n","import zipfile\n","urlretrieve(f\"https://files.grouplens.org/datasets/movielens/{dataset_name}.zip\", \"movielens.zip\")\n","zipfile.ZipFile(\"movielens.zip\", \"r\").extractall()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1667642237989,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"vhrmXmjSh5jf"},"outputs":[],"source":["movies = pd.read_csv(f\"{dataset_name}/movies.csv\")\n","genre_cols = [\n","    \"(no genres listed)\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n","    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n","    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n","]\n","movies"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1667642237990,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"HipV8C2ziAUh"},"outputs":[],"source":["tags = pd.read_csv(f\"{dataset_name}/tags.csv\")\n","tags"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1667642237990,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"RF0KOsiadLM1"},"outputs":[],"source":["ratings = pd.read_csv(f\"{dataset_name}/ratings.csv\")\n","ratings"]},{"cell_type":"markdown","metadata":{"id":"OzxFHwzLy2vU"},"source":["# 5 Backup Models Definition"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"elapsed":473,"status":"error","timestamp":1667642260421,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"U0Q4UEcMy6g6","outputId":"62577a20-91f8-43cf-8ea8-5d9138fa711a"},"outputs":[],"source":["from recommenders.utils.timer import Timer\n","from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n","from recommenders.utils.constants import (\n","    COL_DICT,\n","    DEFAULT_K,\n","    DEFAULT_USER_COL,\n","    DEFAULT_ITEM_COL,\n","    DEFAULT_RATING_COL,\n","    DEFAULT_PREDICTION_COL,\n","    DEFAULT_TIMESTAMP_COL,\n","    SEED,\n",")\n","\n","# Helpers\n","from tempfile import TemporaryDirectory\n","tmp_dir = TemporaryDirectory()\n","TRAIN_FILE = os.path.join(tmp_dir.name, \"df_train.csv\")\n","TEST_FILE = os.path.join(tmp_dir.name, \"df_test.csv\")\n","\n","from recommenders.evaluation.python_evaluation import (\n","    map_at_k,\n","    ndcg_at_k,\n","    precision_at_k,\n","    recall_at_k,\n",")\n","def ranking_metrics_python(test, predictions, k=DEFAULT_K):\n","    return {\n","        \"MAP\": map_at_k(test, predictions, k=k, **COL_DICT),\n","        \"nDCG@k\": ndcg_at_k(test, predictions, k=k, **COL_DICT),\n","        \"Precision@k\": precision_at_k(test, predictions, k=k, **COL_DICT),\n","        \"Recall@k\": recall_at_k(test, predictions, k=k, **COL_DICT),\n","    }\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"elapsed":6,"status":"error","timestamp":1667642261027,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"kBSE8h2MzB16","outputId":"cfd4e3c0-5af3-4a2d-f1ea-dddfcadbd897"},"outputs":[{"ename":"RuntimeError","evalue":"Java gateway process exited before sending its port number","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20048/833106102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspark_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstart_or_get_spark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_or_get_spark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PySpark\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"32g\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"spark.sql.analyzer.failAmbiguousSelfJoin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"false\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmovielens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\recommenders\\utils\\spark_utils.py\u001b[0m in \u001b[0;36mstart_or_get_spark\u001b[1;34m(app_name, url, memory, config, packages, jars, repositories)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mspark_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"getOrCreate()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspark_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\recommenders\\utils\\spark_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                         \u001b[1;31m# This SparkContext may be an existing one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                     \u001b[1;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                     \u001b[1;31m# by all sessions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\anaconda3\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"]}],"source":["from recommenders.utils.spark_utils import start_or_get_spark\n","spark = start_or_get_spark(\"PySpark\", memory=\"32g\")\n","spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n","\n","from recommenders.datasets import movielens\n","from recommenders.datasets.python_splitters import python_stratified_split\n","import os\n","\n","# fix random seeds to make sure out runs are reproducible\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)"]},{"cell_type":"markdown","metadata":{"id":"3ik1fSYis21e"},"source":["### ALS"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1667642261028,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"etb1IkQvs3FU"},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField\n","from pyspark.sql.types import FloatType, IntegerType, LongType\n","from pyspark.ml.recommendation import ALS\n","\n","\n","def prepare_training_als(train, test):\n","    schema = StructType(\n","        (\n","            StructField(DEFAULT_USER_COL, IntegerType()),\n","            StructField(DEFAULT_ITEM_COL, IntegerType()),\n","            StructField(DEFAULT_RATING_COL, FloatType()),\n","            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n","        )\n","    )\n","    spark = start_or_get_spark()\n","    return spark.createDataFrame(train, schema).cache()\n","\n","def prepare_metrics_als(train, test):\n","    schema = StructType(\n","        (\n","            StructField(DEFAULT_USER_COL, IntegerType()),\n","            StructField(DEFAULT_ITEM_COL, IntegerType()),\n","            StructField(DEFAULT_RATING_COL, FloatType()),\n","            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n","        )\n","    )\n","    spark = start_or_get_spark()\n","    return spark.createDataFrame(train, schema).cache(), spark.createDataFrame(test, schema).cache()\n","\n","def predict_als(model, test):\n","    with Timer() as t:\n","        preds = model.transform(test)\n","    return preds, t\n","\n","def train_als(params, data):\n","    symbol = ALS(**params)\n","    with Timer() as t:\n","        model = symbol.fit(data)\n","    return model, t\n","\n","def recommend_k_als(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        # Get the cross join of all user-item pairs and score them.\n","        users = train.select(DEFAULT_USER_COL).distinct()\n","        items = train.select(DEFAULT_ITEM_COL).distinct()\n","        user_item = users.crossJoin(items)\n","        dfs_pred = model.transform(user_item)\n","\n","        # Remove seen items\n","        dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n","            train.alias(\"train\"),\n","            (dfs_pred[DEFAULT_USER_COL] == train[DEFAULT_USER_COL])\n","            & (dfs_pred[DEFAULT_ITEM_COL] == train[DEFAULT_ITEM_COL]),\n","            how=\"outer\",\n","        )\n","        topk_scores = dfs_pred_exclude_train.filter(\n","            dfs_pred_exclude_train[\"train.\" + DEFAULT_RATING_COL].isNull()\n","        ).select(\n","            \"pred.\" + DEFAULT_USER_COL,\n","            \"pred.\" + DEFAULT_ITEM_COL,\n","            \"pred.\" + DEFAULT_PREDICTION_COL,\n","        )\n","    return topk_scores, t\n","\n","\n","als_params = {\n","    \"rank\": 10,\n","    \"maxIter\": 20,\n","    \"implicitPrefs\": False,\n","    \"alpha\": 0.1,\n","    \"regParam\": 0.05,\n","    \"coldStartStrategy\": \"drop\",\n","    \"nonnegative\": False,\n","    \"userCol\": DEFAULT_USER_COL,\n","    \"itemCol\": DEFAULT_ITEM_COL,\n","    \"ratingCol\": DEFAULT_RATING_COL,\n","}"]},{"cell_type":"markdown","metadata":{"id":"M5QhzXoRr0b6"},"source":["### NCF"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1667642261028,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"28jUVetSy9As"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tf_slim'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20048/1686621910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncf_singlenode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNCF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mNCFDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_training_ncf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#df_train.sort_values([\"userID\"], axis=0, ascending=[True], inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\recommenders\\models\\ncf\\ncf_singlenode.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtf_slim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_slim'"]}],"source":["from recommenders.models.ncf.ncf_singlenode import NCF\n","from recommenders.models.ncf.dataset import Dataset as NCFDataset\n","\n","def prepare_training_ncf(df_train, df_test):\n","    #df_train.sort_values([\"userID\"], axis=0, ascending=[True], inplace=True)\n","    #df_test.sort_values([\"userID\"], axis=0, ascending=[True], inplace=True)\n","    train = df_train.sort_values([\"userID\"], axis=0, ascending=[True])\n","    test = df_test.sort_values([\"userID\"], axis=0, ascending=[True])\n","    test = test[df_test[\"userID\"].isin(train[\"userID\"].unique())]\n","    test = test[test[\"itemID\"].isin(train[\"itemID\"].unique())]\n","    train.to_csv(TRAIN_FILE, index=False)\n","    test.to_csv(TEST_FILE, index=False)\n","    return NCFDataset(\n","        train_file=TRAIN_FILE,\n","        col_user=DEFAULT_USER_COL,\n","        col_item=DEFAULT_ITEM_COL,\n","        col_rating=DEFAULT_RATING_COL,\n","        seed=SEED,\n","    )\n","\n","\n","def train_ncf(params, data):\n","    model = NCF(n_users=data.n_users, n_items=data.n_items, **params)\n","    with Timer() as t:\n","        model.fit(data)\n","    return model, t\n","\n","\n","def recommend_k_ncf(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        users, items, preds = [], [], []\n","        item = list(train[DEFAULT_ITEM_COL].unique())\n","        for user in train[DEFAULT_USER_COL].unique():\n","            user = [user] * len(item)\n","            users.extend(user)\n","            items.extend(item)\n","            preds.extend(list(model.predict(user, item, is_list=True)))\n","        topk_scores = pd.DataFrame(\n","            data={\n","                DEFAULT_USER_COL: users,\n","                DEFAULT_ITEM_COL: items,\n","                DEFAULT_PREDICTION_COL: preds,\n","            }\n","        )\n","        merged = pd.merge(\n","            train, topk_scores, on=[DEFAULT_USER_COL, DEFAULT_ITEM_COL], how=\"outer\"\n","        )\n","        topk_scores = merged[merged[DEFAULT_RATING_COL].isnull()].drop(\n","            DEFAULT_RATING_COL, axis=1\n","        )\n","    # Remove temp files\n","    return topk_scores, t\n","\n","ncf_params = {\n","    \"model_type\": \"NeuMF\",\n","    \"n_factors\": 4,\n","    \"layer_sizes\": [16, 8, 4],\n","    \"n_epochs\": 20,\n","    \"batch_size\": 1024,\n","    \"learning_rate\": 1e-3,\n","    \"verbose\": 10\n","}"]},{"cell_type":"markdown","metadata":{"id":"pIDpds_1tSxY"},"source":["### KGAT"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1667642261029,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"juTZLU9ktSxZ"},"outputs":[],"source":["#%pip install easydict\n","import os\n","import sys\n","import random\n","from time import time\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from KGAT_folder.KGAT import KGAT\n","from KGAT_folder.log_helper import *\n","from KGAT_folder.parser_kgat import *\n","from KGAT_folder.metrics import *\n","from KGAT_folder.model_helper import *\n","from KGAT_folder.loader_kgat import DataLoaderKGAT\n","\n","\n","def train_kgat():\n","    args = parse_kgat_args()\n","    #train(args)\n","    time0 = time()\n","    model, data, Ks, device = train(args)\n","    time1 = time()\n","    t = time1-time0\n","    return model, data, Ks, device, t\n","\n","def evaluate_kgat(model, dataloader, Ks, device):\n","    test_batch_size = dataloader.test_batch_size\n","    train_user_dict = dataloader.train_user_dict\n","    test_user_dict = dataloader.test_user_dict\n","\n","    model.eval()\n","\n","    user_ids = list(test_user_dict.keys())\n","    user_ids_batches = [user_ids[i: i + test_batch_size] for i in range(0, len(user_ids), test_batch_size)]\n","    user_ids_batches = [torch.LongTensor(d) for d in user_ids_batches]\n","\n","    n_items = dataloader.n_items\n","    item_ids = torch.arange(n_items, dtype=torch.long).to(device)\n","\n","    cf_scores = []\n","    metric_names = ['precision', 'recall', 'ndcg']\n","    metrics_dict = {k: {m: [] for m in metric_names} for k in Ks}\n","\n","    with tqdm(total=len(user_ids_batches), desc='Evaluating Iteration') as pbar:\n","        for batch_user_ids in user_ids_batches:\n","            batch_user_ids = batch_user_ids.to(device)\n","\n","            with torch.no_grad():\n","                batch_scores = model(batch_user_ids, item_ids, mode='predict')       # (n_batch_users, n_items)\n","\n","            batch_scores = batch_scores.cpu()\n","            batch_metrics = calc_metrics_at_k(batch_scores, train_user_dict, test_user_dict, batch_user_ids.cpu().numpy(), item_ids.cpu().numpy(), Ks)\n","\n","            cf_scores.append(batch_scores.numpy())\n","            for k in Ks:\n","                for m in metric_names:\n","                    metrics_dict[k][m].append(batch_metrics[k][m])\n","            pbar.update(1)\n","\n","    cf_scores = np.concatenate(cf_scores, axis=0)\n","    for k in Ks:\n","        for m in metric_names:\n","            metrics_dict[k][m] = np.concatenate(metrics_dict[k][m]).mean()\n","    return cf_scores, metrics_dict\n","\n","\n","def train(args):\n","    # seed\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.cuda.manual_seed_all(args.seed)\n","\n","    #log_save_id = create_log_id(args.save_dir)\n","    #logging_config(folder=args.save_dir, name='log{:d}'.format(log_save_id), no_console=False)\n","    #logging.info(args)\n","\n","    # GPU / CPU\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # load data\n","    data = DataLoaderKGAT(args, logging)\n","    if args.use_pretrain == 1:\n","        user_pre_embed = torch.tensor(data.user_pre_embed)\n","        item_pre_embed = torch.tensor(data.item_pre_embed)\n","    else:\n","        user_pre_embed, item_pre_embed = None, None\n","\n","    # construct model & optimizer\n","    model = KGAT(args, data.n_users, data.n_entities, data.n_relations, data.A_in, user_pre_embed, item_pre_embed)\n","    #if args.use_pretrain == 2:\n","    #    model = load_model(model, args.pretrain_model_path)\n","\n","    model.to(device)\n","    #logging.info(model)\n","\n","    cf_optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","    kg_optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","\n","    # initialize metrics\n","    best_epoch = -1\n","    best_recall = 0\n","\n","    Ks = eval(args.Ks)\n","    k_min = min(Ks)\n","    k_max = max(Ks)\n","\n","    epoch_list = []\n","    metrics_list = {k: {'precision': [], 'recall': [], 'ndcg': []} for k in Ks}\n","\n","    # train model\n","    for epoch in range(1, args.n_epoch + 1):\n","        time0 = time()\n","        model.train()\n","\n","        # train cf\n","        time1 = time()\n","        cf_total_loss = 0\n","        n_cf_batch = data.n_cf_train // data.cf_batch_size + 1\n","\n","        for iter in range(1, n_cf_batch + 1):\n","            time2 = time()\n","            cf_batch_user, cf_batch_pos_item, cf_batch_neg_item = data.generate_cf_batch(data.train_user_dict, data.cf_batch_size)\n","            cf_batch_user = cf_batch_user.to(device)\n","            cf_batch_pos_item = cf_batch_pos_item.to(device)\n","            cf_batch_neg_item = cf_batch_neg_item.to(device)\n","\n","            cf_batch_loss = model(cf_batch_user, cf_batch_pos_item, cf_batch_neg_item, mode='train_cf')\n","\n","            if np.isnan(cf_batch_loss.cpu().detach().numpy()):\n","                logging.info('ERROR (CF Training): Epoch {:04d} Iter {:04d} / {:04d} Loss is nan.'.format(epoch, iter, n_cf_batch))\n","                sys.exit()\n","\n","            cf_batch_loss.backward()\n","            cf_optimizer.step()\n","            cf_optimizer.zero_grad()\n","            cf_total_loss += cf_batch_loss.item()\n","\n","            if (iter % args.cf_print_every) == 0:\n","                logging.info('CF Training: Epoch {:04d} Iter {:04d} / {:04d} | Time {:.1f}s | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(epoch, iter, n_cf_batch, time() - time2, cf_batch_loss.item(), cf_total_loss / iter))\n","        logging.info('CF Training: Epoch {:04d} Total Iter {:04d} | Total Time {:.1f}s | Iter Mean Loss {:.4f}'.format(epoch, n_cf_batch, time() - time1, cf_total_loss / n_cf_batch))\n","\n","        # train kg\n","        time3 = time()\n","        kg_total_loss = 0\n","        n_kg_batch = data.n_kg_train // data.kg_batch_size + 1\n","\n","        for iter in range(1, n_kg_batch + 1):\n","            time4 = time()\n","            kg_batch_head, kg_batch_relation, kg_batch_pos_tail, kg_batch_neg_tail = data.generate_kg_batch(data.train_kg_dict, data.kg_batch_size, data.n_users_entities)\n","            kg_batch_head = kg_batch_head.to(device)\n","            kg_batch_relation = kg_batch_relation.to(device)\n","            kg_batch_pos_tail = kg_batch_pos_tail.to(device)\n","            kg_batch_neg_tail = kg_batch_neg_tail.to(device)\n","\n","            kg_batch_loss = model(kg_batch_head, kg_batch_relation, kg_batch_pos_tail, kg_batch_neg_tail, mode='train_kg')\n","\n","            if np.isnan(kg_batch_loss.cpu().detach().numpy()):\n","                logging.info('ERROR (KG Training): Epoch {:04d} Iter {:04d} / {:04d} Loss is nan.'.format(epoch, iter, n_kg_batch))\n","                sys.exit()\n","\n","            kg_batch_loss.backward()\n","            kg_optimizer.step()\n","            kg_optimizer.zero_grad()\n","            kg_total_loss += kg_batch_loss.item()\n","\n","            if (iter % args.kg_print_every) == 0:\n","                logging.info('KG Training: Epoch {:04d} Iter {:04d} / {:04d} | Time {:.1f}s | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(epoch, iter, n_kg_batch, time() - time4, kg_batch_loss.item(), kg_total_loss / iter))\n","        logging.info('KG Training: Epoch {:04d} Total Iter {:04d} | Total Time {:.1f}s | Iter Mean Loss {:.4f}'.format(epoch, n_kg_batch, time() - time3, kg_total_loss / n_kg_batch))\n","\n","        # update attention\n","        time5 = time()\n","        h_list = data.h_list.to(device)\n","        t_list = data.t_list.to(device)\n","        r_list = data.r_list.to(device)\n","        relations = list(data.laplacian_dict.keys())\n","        model(h_list, t_list, r_list, relations, mode='update_att')\n","        logging.info('Update Attention: Epoch {:04d} | Total Time {:.1f}s'.format(epoch, time() - time5))\n","\n","        logging.info('CF + KG Training: Epoch {:04d} | Total Time {:.1f}s'.format(epoch, time() - time0))\n","    return model, data, Ks, device\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"\\nComputing {'KGAT'} algorithm on Movielens {'100k'}\")\n","model, data, Ks, device, time_train = train_kgat()\n","print('time_train: ', time_train)\n","_, metrics_dict_kgat = evaluate_kgat(model, data, Ks, device)\n","print(metrics_dict_kgat)"]},{"cell_type":"markdown","metadata":{"id":"QsJmgwgNsBE8"},"source":["### LightGCN"]},{"cell_type":"markdown","metadata":{},"source":["#### For comparison"]},{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1667642261028,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"BZtl_jr3sA1o"},"outputs":[],"source":["from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n","from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n","    \n","def prepare_training_lightgcn(train, test):\n","    return ImplicitCF(train=train, test=test)\n","\n","def train_lightgcn(params, data):\n","    hparams = prepare_hparams(**params)\n","    model = LightGCN(hparams, data)\n","    with Timer() as t:\n","        model.fit()\n","    return model, t\n","\n","def recommend_k_lightgcn(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        topk_scores = model.recommend_k_items(\n","            test, top_k=top_k, remove_seen=remove_seen\n","        )\n","    return topk_scores, t\n","\n","lightgcn_param = {\n","    #\"yaml_file\": os.path.join(\"drive\", \"MyDrive\", \"4222Group9\", \"lightgcn.yaml\"),\n","    \"yaml_file\": \"lightgcn.yaml\",\n","    \"n_layers\": 3,\n","    \"batch_size\": 1024,\n","    \"epochs\": 10,\n","    \"learning_rate\": 0.005,\n","    \"eval_epoch\": 5,\n","    \"top_k\": DEFAULT_K,\n","    \"stacking_func\": 1, #0: original, 1: exponential decay, 1.5: exponential increase, 2: trainable with random initialization, 3: trainable with unified initialization\n","}"]},{"cell_type":"markdown","metadata":{"id":"W8cmNmNcsIrU"},"source":["## Comparison"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1667642261029,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"WDnMUwTkmaVl"},"outputs":[{"ename":"NameError","evalue":"name 'ncf_params' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20048/1464176471.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m params = {\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"als\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mals_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;34m\"ncf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mncf_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;34m\"lightgcn\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlightgcn_param\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m }\n","\u001b[1;31mNameError\u001b[0m: name 'ncf_params' is not defined"]}],"source":["params = {\n","    \"als\": als_params,\n","    \"ncf\": ncf_params,\n","    \"lightgcn\": lightgcn_param,\n","}\n","prepare_training_data = {\n","    \"als\": prepare_training_als,\n","    \"ncf\": prepare_training_ncf,\n","    \"lightgcn\": prepare_training_lightgcn,\n","}\n","\n","\n","from recommenders.evaluation.spark_evaluation import (\n","    SparkRatingEvaluation,\n","    SparkRankingEvaluation,\n",")\n","def rating_metrics_pyspark(test, predictions):\n","    rating_eval = SparkRatingEvaluation(test, predictions, **COL_DICT)\n","    return {\n","        \"RMSE\": rating_eval.rmse(),\n","        \"MAE\": rating_eval.mae(),\n","        \"R2\": rating_eval.exp_var(),\n","        \"Explained Variance\": rating_eval.rsquared(),\n","    }\n","def ranking_metrics_pyspark(test, predictions, k=DEFAULT_K):\n","    rank_eval = SparkRankingEvaluation(\n","        test, predictions, k=k, relevancy_method=\"top_k\", **COL_DICT\n","    )\n","    return {\n","        \"MAP\": rank_eval.map_at_k(),\n","        \"nDCG@k\": rank_eval.ndcg_at_k(),\n","        \"Precision@k\": rank_eval.precision_at_k(),\n","        \"Recall@k\": rank_eval.recall_at_k(),\n","    }\n","\n","prepare_metrics_data = {\n","    \"als\": lambda train, test: prepare_metrics_als(train, test),\n","}\n","trainer = {\n","    \"als\": lambda params, data: train_als(params, data),\n","    \"ncf\": lambda params, data: train_ncf(params, data),\n","    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n","}\n","rating_predictor = {\n","    \"als\": lambda model, test: predict_als(model, test),\n","}\n","rating_evaluator = {\n","    \"als\": lambda test, predictions: rating_metrics_pyspark(test, predictions)\n","}\n","ranking_predictor = {\n","    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n","    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n","    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n","}\n","ranking_evaluator = {\n","    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n","    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n","    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n","}\n","metrics = {\n","    \"als\": [\"rating\", \"ranking\"],\n","    \"ncf\": [\"ranking\"],\n","    \"lightgcn\": [\"ranking\"]\n","}"]},{"cell_type":"markdown","metadata":{"id":"W8cmNmNcsIrU"},"source":["## Run LightGCN"]},{"cell_type":"code","execution_count":108,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1667642261029,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"WDnMUwTkmaVl"},"outputs":[],"source":["params = {\n","    \"lightgcn\": lightgcn_param,\n","}\n","prepare_training_data = {\n","    \"lightgcn\": prepare_training_lightgcn,\n","}\n","\n","\n","from recommenders.evaluation.spark_evaluation import (\n","    SparkRatingEvaluation,\n","    SparkRankingEvaluation,\n",")\n","def rating_metrics_pyspark(test, predictions):\n","    rating_eval = SparkRatingEvaluation(test, predictions, **COL_DICT)\n","    return {\n","        \"RMSE\": rating_eval.rmse(),\n","        \"MAE\": rating_eval.mae(),\n","        \"R2\": rating_eval.exp_var(),\n","        \"Explained Variance\": rating_eval.rsquared(),\n","    }\n","def ranking_metrics_pyspark(test, predictions, k=DEFAULT_K):\n","    rank_eval = SparkRankingEvaluation(\n","        test, predictions, k=k, relevancy_method=\"top_k\", **COL_DICT\n","    )\n","    return {\n","        \"MAP\": rank_eval.map_at_k(),\n","        \"nDCG@k\": rank_eval.ndcg_at_k(),\n","        \"Precision@k\": rank_eval.precision_at_k(),\n","        \"Recall@k\": rank_eval.recall_at_k(),\n","    }\n","#prepare_metrics_data = {\n","#    \"lightgcn\": lambda train, test: prepare_metrics_lightgcn(train, test),\n","#}\n","trainer = {\n","    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n","}\n","ranking_predictor = {\n","    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n","}\n","ranking_evaluator = {\n","    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n","}\n","metrics = {\n","    \"lightgcn\": [\"ranking\"]\n","}"]},{"cell_type":"markdown","metadata":{"id":"3B4ScYiXzCN1"},"source":["# 6 Hyperparameter Tunning Backup"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def generate_summary(data, algo, k, train_time, time_rating, rating_metrics, time_ranking, ranking_metrics):\n","    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": time_rating, \"Recommending time (s)\": time_ranking}\n","    if rating_metrics is None:\n","        rating_metrics = {\n","            \"RMSE\": np.nan,\n","            \"MAE\": np.nan,\n","            \"R2\": np.nan,\n","            \"Explained Variance\": np.nan,\n","        }\n","    if ranking_metrics is None:\n","        ranking_metrics = {\n","            \"MAP\": np.nan,\n","            \"nDCG@k\": np.nan,\n","            \"Precision@k\": np.nan,\n","            \"Recall@k\": np.nan,\n","        }\n","    summary.update(rating_metrics)\n","    summary.update(ranking_metrics)\n","    return summary"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["data_sizes = [\"100k\"] # Movielens data size: 100k, 1m, 10m, or 20m\n","algorithms = [ \"lightgcn\"]"]},{"cell_type":"markdown","metadata":{},"source":["## Sanity Check by Overfitting on Small Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#!pip install pytorch-lightning\n","from pytorch_lightning import Trainer, seed_everything\n","from LightGCN.code.main_lgcn import sanity_check\n","\n","seed_everything(42, workers=True)\n","\n","model = sanity_check()\n","trainer = Trainer(max_epochs=10000, overfit_batches=0.01)\n","trainer.fit(model)"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of Movielens 100k: (100000, 4)\n","\n","Computing lightgcn algorithm on Movielens 100k\n","Already create adjacency matrix.\n","Already normalize adjacency matrix.\n","Using xavier initialization.\n","Epoch 1 (train)4.7s: train loss = 0.44144 = (mf)0.44135 + (embed)0.00009\n","Epoch 2 (train)4.0s: train loss = 0.22109 = (mf)0.22087 + (embed)0.00021\n","Epoch 3 (train)3.9s: train loss = 0.17843 = (mf)0.17814 + (embed)0.00029\n","Epoch 4 (train)4.1s: train loss = 0.15664 = (mf)0.15629 + (embed)0.00036\n","Epoch 5 (train)4.2s + (eval)0.5s: train loss = 0.14531 = (mf)0.14490 + (embed)0.00042, recall = 0.19207, ndcg = 0.40299, precision = 0.35101, map = 0.11538\n","Epoch 6 (train)3.9s: train loss = 0.13200 = (mf)0.13153 + (embed)0.00047\n","Epoch 7 (train)3.9s: train loss = 0.12285 = (mf)0.12232 + (embed)0.00053\n","Epoch 8 (train)3.9s: train loss = 0.11487 = (mf)0.11429 + (embed)0.00059\n","Epoch 9 (train)3.9s: train loss = 0.10552 = (mf)0.10488 + (embed)0.00064\n","Epoch 10 (train)3.9s + (eval)0.3s: train loss = 0.10084 = (mf)0.10014 + (embed)0.00070, recall = 0.19891, ndcg = 0.41878, precision = 0.36416, map = 0.12154\n","Training time: 41.1424s\n","Ranking prediction time: 0.0709s\n","\n","Computation finished\n"]}],"source":["data_sizes = [\"100k\"] # Movielens data size: 100k, 1m, 10m, or 20m\n","algorithms = [ \"lightgcn\"]\n","#%%time\n","from recommenders.datasets import movielens\n","from recommenders.datasets.python_splitters import python_stratified_split\n","# For each data size and each algorithm, a recommender is evaluated. \n","cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n","df_results = pd.DataFrame(columns=cols)\n","\n","for data_size in data_sizes:\n","\n","    # Load the dataset\n","    #df = movielens.load_pandas_df(\n","    #    size=data_size,\n","    #    header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n","    #)\n","    if data_size=='100k':\n","        df = pd.read_csv('ml-100k/u.data', sep='\\t', header=None)\n","    df.columns = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n","    df[DEFAULT_RATING_COL] = df[DEFAULT_RATING_COL].astype(float)\n","    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n","    \n","    # Split the dataset\n","    df_train, df_test = python_stratified_split(df,\n","                                                ratio=0.75, \n","                                                min_rating=1, \n","                                                filter_by=\"item\", \n","                                                col_user=DEFAULT_USER_COL, \n","                                                col_item=DEFAULT_ITEM_COL,\n","                                                )\n","\n","    #df_train = \"../LightGCN/data/movielens/train.txt\"\n","    # Loop through the algos\n","    for algo in algorithms:\n","        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n","        if algo == 'kgat':\n","            model, data, Ks, device, time_train = train_kgat()\n","            _, metrics_dict_kgat = evaluate_kgat(model, data, Ks, device)\n","            print(metrics_dict_kgat)\n","            # Record results\n","            #summary = generate_summary('100k', algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            #df_results.loc[df_results.shape[0] + 1] = summary\n","            \n","        else:\n","            # Data prep for training set\n","            train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            \n","            # Get model parameters\n","            model_params = params[algo]\n","            \n","            # Train the model\n","            model, time_train = trainer[algo](model_params, train)\n","            print(f\"Training time: {time_train}s\")\n","                    \n","            # Predict and evaluate\n","            #train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            train, test = df_train, df_test\n","            \n","            if \"rating\" in metrics[algo]:   \n","                # Predict for rating\n","                preds, time_rating = rating_predictor[algo](model, test)\n","                print(f\"Rating prediction time: {time_rating}s\")\n","                \n","                # Evaluate for rating\n","                ratings = rating_evaluator[algo](test, preds)\n","            else:\n","                ratings = None\n","                time_rating = np.nan\n","            \n","            if \"ranking\" in metrics[algo]:\n","                # Predict for ranking\n","                top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n","                print(f\"Ranking prediction time: {time_ranking}s\")\n","                \n","                # Evaluate for rating\n","                rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n","            else:\n","                rankings = None\n","                time_ranking = np.nan\n","                \n","            # Record results\n","            summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            df_results.loc[df_results.shape[0] + 1] = summary\n","        \n","print(\"\\nComputation finished\")"]},{"cell_type":"markdown","metadata":{},"source":["## Training Plot"]},{"cell_type":"markdown","metadata":{},"source":["click \"launch TensorBoard Session\" in main_lgcn.py"]},{"cell_type":"markdown","metadata":{},"source":["# 7 Comparisons on Movielens and Movie"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1667642261031,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"8reKYmEH2d-k"},"outputs":[],"source":["data_sizes = [\"100k\",\"1m\"] # Movielens data size: 100k, 1m, 10m, or 20m\n","#algorithms = [ \"lightgcn\"]\n","algorithms = [\"als\", \"ncf\", \"lightgcn\", \"kgat\"]"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1667642261031,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"-17fyWdVmiHM"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pandera'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\recommenders\\datasets\\movielens.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mpass\u001b[0m  \u001b[1;31m# so the environment without spark doesn't break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandera\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandera\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandera'"]}],"source":["%%time\n","\n","# For each data size and each algorithm, a recommender is evaluated. \n","cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n","df_results = pd.DataFrame(columns=cols)\n","\n","for data_size in data_sizes:\n","    # Load the dataset\n","    df = movielens.load_pandas_df(\n","        size=data_size,\n","        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n","    )\n","    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n","    \n","    # Split the dataset\n","    df_train, df_test = python_stratified_split(df,\n","                                                ratio=0.75, \n","                                                min_rating=1, \n","                                                filter_by=\"item\", \n","                                                col_user=DEFAULT_USER_COL, \n","                                                col_item=DEFAULT_ITEM_COL\n","                                                )\n","   \n","    # Loop through the algos\n","    for algo in algorithms:\n","        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n","        if algo == 'kgat':\n","            model, data, Ks, device, time_train = train_kgat()\n","            _, metrics_dict_kgat = evaluate_kgat(model, data, Ks, device)\n","            print(metrics_dict_kgat)\n","            # Record results\n","            #summary = generate_summary('100k', algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            #df_results.loc[df_results.shape[0] + 1] = summary\n","            \n","        else:\n","            # Data prep for training set\n","            train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            \n","            # Get model parameters\n","            model_params = params[algo]\n","            \n","            # Train the model\n","            model, time_train = trainer[algo](model_params, train)\n","            print(f\"Training time: {time_train}s\")\n","                    \n","            # Predict and evaluate\n","            train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            \n","            if \"rating\" in metrics[algo]:   \n","                # Predict for rating\n","                preds, time_rating = rating_predictor[algo](model, test)\n","                print(f\"Rating prediction time: {time_rating}s\")\n","                \n","                # Evaluate for rating\n","                ratings = rating_evaluator[algo](test, preds)\n","            else:\n","                ratings = None\n","                time_rating = np.nan\n","            \n","            if \"ranking\" in metrics[algo]:\n","                # Predict for ranking\n","                top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n","                print(f\"Ranking prediction time: {time_ranking}s\")\n","                \n","                # Evaluate for rating\n","                rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n","            else:\n","                rankings = None\n","                time_ranking = np.nan\n","                \n","            # Record results\n","            summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            df_results.loc[df_results.shape[0] + 1] = summary\n","        \n","print(\"\\nComputation finished\")"]},{"cell_type":"markdown","metadata":{},"source":["## Print the result summary"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1667642261031,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"36QRfkqVrYzi"},"outputs":[],"source":["df_results"]},{"cell_type":"markdown","metadata":{"id":"seUWygXTzYfc"},"source":["# 8 Credit and Reference\n","\n","1. https://github.com/microsoft/recommenders"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"8006cd3f4b5a31b91c77e5b5a521798c8412e8b93831dc7973f670e0263ddfcb"}}},"nbformat":4,"nbformat_minor":0}
