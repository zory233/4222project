{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR) \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "import tensorflow as tf # NOTE: TF needs to be imported before PyTorch, otherwise we get a weird initialization error\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "import torch\n",
    "import fastai\n",
    "import surprise\n",
    "import cornac\n",
    "\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "from recommenders.utils.general_utils import get_number_processors\n",
    "from recommenders.utils.gpu_utils import get_cuda_version, get_cudnn_version\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.models.fastai.fastai_utils import hide_fastai_progress_bar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = [\"10m\", \"20m\"] # For augmentation purposes\n",
    "data_sizes2 = [\"50k\",\"40k\",\"30k\"] # For reducing 100k dataset\n",
    "\n",
    "algorithms = [\"als\", \"svd\", \"sar\", \"ncf\", \"fastai\", \"bpr\", \"bivae\", \"lightgcn\"]\n",
    "# Main focus on LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(f\"{dataset_name}/tags.csv\")\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(f\"{dataset_name}/ratings.csv\")\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(f\"{dataset_name}/movies.csv\")\n",
    "genre_cols = [\n",
    "    \"(no genres listed)\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()\n",
    "\n",
    "#Dispaly here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "\n",
    "def prepare_training_als(train, test):\n",
    "    schema = StructType(\n",
    "        (\n",
    "            StructField(DEFAULT_USER_COL, IntegerType()),\n",
    "            StructField(DEFAULT_ITEM_COL, IntegerType()),\n",
    "            StructField(DEFAULT_RATING_COL, FloatType()),\n",
    "            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n",
    "        )\n",
    "    )\n",
    "    spark = start_or_get_spark()\n",
    "    return spark.createDataFrame(train, schema).cache()\n",
    "\n",
    "def prepare_metrics_als(train, test):\n",
    "    schema = StructType(\n",
    "        (\n",
    "            StructField(DEFAULT_USER_COL, IntegerType()),\n",
    "            StructField(DEFAULT_ITEM_COL, IntegerType()),\n",
    "            StructField(DEFAULT_RATING_COL, FloatType()),\n",
    "            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n",
    "        )\n",
    "    )\n",
    "    spark = start_or_get_spark()\n",
    "    return spark.createDataFrame(train, schema).cache(), spark.createDataFrame(test, schema).cache()\n",
    "\n",
    "def predict_als(model, test):\n",
    "    with Timer() as t:\n",
    "        preds = model.transform(test)\n",
    "    return preds, t\n",
    "\n",
    "def train_als(params, data):\n",
    "    symbol = ALS(**params)\n",
    "    with Timer() as t:\n",
    "        model = symbol.fit(data)\n",
    "    return model, t\n",
    "\n",
    "def recommend_k_als(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n",
    "    with Timer() as t:\n",
    "        # Get the cross join of all user-item pairs and score them.\n",
    "        users = train.select(DEFAULT_USER_COL).distinct()\n",
    "        items = train.select(DEFAULT_ITEM_COL).distinct()\n",
    "        user_item = users.crossJoin(items)\n",
    "        dfs_pred = model.transform(user_item)\n",
    "\n",
    "        # Remove seen items\n",
    "        dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "            train.alias(\"train\"),\n",
    "            (dfs_pred[DEFAULT_USER_COL] == train[DEFAULT_USER_COL])\n",
    "            & (dfs_pred[DEFAULT_ITEM_COL] == train[DEFAULT_ITEM_COL]),\n",
    "            how=\"outer\",\n",
    "        )\n",
    "        topk_scores = dfs_pred_exclude_train.filter(\n",
    "            dfs_pred_exclude_train[\"train.\" + DEFAULT_RATING_COL].isNull()\n",
    "        ).select(\n",
    "            \"pred.\" + DEFAULT_USER_COL,\n",
    "            \"pred.\" + DEFAULT_ITEM_COL,\n",
    "            \"pred.\" + DEFAULT_PREDICTION_COL,\n",
    "        )\n",
    "    return topk_scores, t\n",
    "\n",
    "\n",
    "als_params = {\n",
    "    \"rank\": 10,\n",
    "    \"maxIter\": 20,\n",
    "    \"implicitPrefs\": False,\n",
    "    \"alpha\": 0.1,\n",
    "    \"regParam\": 0.05,\n",
    "    \"coldStartStrategy\": \"drop\",\n",
    "    \"nonnegative\": False,\n",
    "    \"userCol\": DEFAULT_USER_COL,\n",
    "    \"itemCol\": DEFAULT_ITEM_COL,\n",
    "    \"ratingCol\": DEFAULT_RATING_COL,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
