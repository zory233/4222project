{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/zory233/4222project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"vobP7ahXP1EG"},"source":["# Graph-Learning-Based Recommender System on MovieLens\n","\n","### Group 9\n","\n","- AGARWAL, Sahil\n","- WEI, Yuanjing\n","- ZHANG, Yujun yzhanglo@connect.ust.hk\n","\n","Group project of COMP4222@HKUST in 2022 Fall."]},{"cell_type":"markdown","metadata":{"id":"QpTqYz7qYJbP"},"source":["# 1 Environment Configuration"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"MXxR7IpwI83o","colab":{"base_uri":"https://localhost:8080/","height":603},"executionInfo":{"status":"error","timestamp":1667642237984,"user_tz":-480,"elapsed":30299,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}},"outputId":"9933f848-12fa-442f-afe4-0d95a20a464e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","[Errno 2] No such file or directory: '/content/drive/MyDrive/4222Group9'\n","/content\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7e7ce898e502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'/content/drive/MyDrive/4222Group9'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mcomp4222\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'-'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'comp4222'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7e7ce898e502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install recommenders[examples,gpu,spark]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mcomp4222\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'comp4222'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd '/content/drive/MyDrive/4222Group9'\n","    import comp4222\n","    %cd '-'\n","    \n","    %pip install recommenders[examples,gpu,spark]\n","except:\n","    import comp4222\n","\n","%pwd\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RuvfqktV-jm","executionInfo":{"status":"aborted","timestamp":1667642237987,"user_tz":-480,"elapsed":14,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import torch\n","\n","# easier to print by putting variable as a single line\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","# make matplotlib figures appear inline in the notebook rather than in a new window.\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# Add some convenience functions to Pandas DataFrame.\n","pd.options.display.max_rows = 10\n","pd.options.display.float_format = '{:.2f}'.format\n","def mask(df, key, function):\n","  \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n","  return df[function(df[key])]\n","\n","def flatten_cols(df):\n","  df.columns = [' '.join(col).strip() for col in df.columns.values]\n","  return df\n","\n","pd.DataFrame.mask = mask\n","pd.DataFrame.flatten_cols = flatten_cols\n","\n","# http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["from comp4222 import b\n","comp4222.b.ok()"],"metadata":{"id":"zLFdbrlyOWiT","executionInfo":{"status":"aborted","timestamp":1667642237988,"user_tz":-480,"elapsed":15,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6BddvnBzjdYd","executionInfo":{"status":"aborted","timestamp":1667642237988,"user_tz":-480,"elapsed":15,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkgjzCmnWXUw"},"source":["# 2 MovieLens\n"]},{"cell_type":"markdown","metadata":{"id":"Mq_PrL0LZrGa"},"source":["We're using ml-latest-small from MovieLens. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018. The readme.md is avaliable [here](https://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)."]},{"cell_type":"markdown","metadata":{"id":"g_XRmlt-yMUu"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vt7THxaKWZDv","executionInfo":{"status":"aborted","timestamp":1667642237989,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["# Download MovieLens data.\n","dataset_name = \"ml-latest-small\"\n","from urllib.request import urlretrieve\n","import zipfile\n","urlretrieve(f\"https://files.grouplens.org/datasets/movielens/{dataset_name}.zip\", \"movielens.zip\")\n","zipfile.ZipFile(\"movielens.zip\", \"r\").extractall()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhrmXmjSh5jf","executionInfo":{"status":"aborted","timestamp":1667642237989,"user_tz":-480,"elapsed":15,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["movies = pd.read_csv(f\"{dataset_name}/movies.csv\")\n","genre_cols = [\n","    \"(no genres listed)\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n","    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n","    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n","]\n","movies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HipV8C2ziAUh","executionInfo":{"status":"aborted","timestamp":1667642237990,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["tags = pd.read_csv(f\"{dataset_name}/tags.csv\")\n","tags"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RF0KOsiadLM1","executionInfo":{"status":"aborted","timestamp":1667642237990,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["ratings = pd.read_csv(f\"{dataset_name}/ratings.csv\")\n","ratings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ljcMdSLjd9Fo","executionInfo":{"status":"aborted","timestamp":1667642237990,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WInj7jSdojH","executionInfo":{"status":"aborted","timestamp":1667642237990,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"giSgiu7jyO04"},"source":["## Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5tJTHDFXmd7","executionInfo":{"status":"aborted","timestamp":1667642237991,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["# %pip install altair\n","import altair as alt\n","alt.data_transformers.enable('default', max_rows=None)\n","alt.renderers.enable('colab')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNNLzS6uyRBI","executionInfo":{"status":"aborted","timestamp":1667642237991,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"07D747O0yleD","executionInfo":{"status":"aborted","timestamp":1667642237992,"user_tz":-480,"elapsed":17,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yIDqnYvByqGx"},"source":["# 3 Preliminaries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQO0Ie-xyxut","executionInfo":{"status":"aborted","timestamp":1667642237992,"user_tz":-480,"elapsed":17,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"OzxFHwzLy2vU"},"source":["# 4 Models"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"U0Q4UEcMy6g6","executionInfo":{"status":"error","timestamp":1667642260421,"user_tz":-480,"elapsed":473,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}},"colab":{"base_uri":"https://localhost:8080/","height":377},"outputId":"62577a20-91f8-43cf-8ea8-5d9138fa711a"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a30b58022c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeeprec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeeprec_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare_hparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from recommenders.utils.constants import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mCOL_DICT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mDEFAULT_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'recommenders'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from recommenders.utils.timer import Timer\n","from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n","from recommenders.utils.constants import (\n","    COL_DICT,\n","    DEFAULT_K,\n","    DEFAULT_USER_COL,\n","    DEFAULT_ITEM_COL,\n","    DEFAULT_RATING_COL,\n","    DEFAULT_PREDICTION_COL,\n","    DEFAULT_TIMESTAMP_COL,\n","    SEED,\n",")\n","\n","# Helpers\n","from tempfile import TemporaryDirectory\n","tmp_dir = TemporaryDirectory()\n","TRAIN_FILE = os.path.join(tmp_dir.name, \"df_train.csv\")\n","TEST_FILE = os.path.join(tmp_dir.name, \"df_test.csv\")\n","\n","from recommenders.evaluation.python_evaluation import (\n","    map_at_k,\n","    ndcg_at_k,\n","    precision_at_k,\n","    recall_at_k,\n",")\n","def ranking_metrics_python(test, predictions, k=DEFAULT_K):\n","    return {\n","        \"MAP\": map_at_k(test, predictions, k=k, **COL_DICT),\n","        \"nDCG@k\": ndcg_at_k(test, predictions, k=k, **COL_DICT),\n","        \"Precision@k\": precision_at_k(test, predictions, k=k, **COL_DICT),\n","        \"Recall@k\": recall_at_k(test, predictions, k=k, **COL_DICT),\n","    }\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kBSE8h2MzB16","executionInfo":{"status":"error","timestamp":1667642261027,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}},"colab":{"base_uri":"https://localhost:8080/","height":377},"outputId":"cfd4e3c0-5af3-4a2d-f1ea-dddfcadbd897"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c1fa335aba9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstart_or_get_spark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_or_get_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySpark\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"32g\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.analyzer.failAmbiguousSelfJoin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"false\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmovielens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'recommenders'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from recommenders.utils.spark_utils import start_or_get_spark\n","spark = start_or_get_spark(\"PySpark\", memory=\"32g\")\n","spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n","\n","from recommenders.datasets import movielens\n","from recommenders.datasets.python_splitters import python_stratified_split\n","import os\n","\n","# fix random seeds to make sure out runs are reproducible\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)"]},{"cell_type":"markdown","source":["## ALS"],"metadata":{"id":"3ik1fSYis21e"}},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField\n","from pyspark.sql.types import FloatType, IntegerType, LongType\n","from pyspark.ml.recommendation import ALS\n","\n","\n","def prepare_training_als(train, test):\n","    schema = StructType(\n","        (\n","            StructField(DEFAULT_USER_COL, IntegerType()),\n","            StructField(DEFAULT_ITEM_COL, IntegerType()),\n","            StructField(DEFAULT_RATING_COL, FloatType()),\n","            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n","        )\n","    )\n","    spark = start_or_get_spark()\n","    return spark.createDataFrame(train, schema).cache()\n","\n","def prepare_metrics_als(train, test):\n","    schema = StructType(\n","        (\n","            StructField(DEFAULT_USER_COL, IntegerType()),\n","            StructField(DEFAULT_ITEM_COL, IntegerType()),\n","            StructField(DEFAULT_RATING_COL, FloatType()),\n","            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n","        )\n","    )\n","    spark = start_or_get_spark()\n","    return spark.createDataFrame(train, schema).cache(), spark.createDataFrame(test, schema).cache()\n","\n","def predict_als(model, test):\n","    with Timer() as t:\n","        preds = model.transform(test)\n","    return preds, t\n","\n","def train_als(params, data):\n","    symbol = ALS(**params)\n","    with Timer() as t:\n","        model = symbol.fit(data)\n","    return model, t\n","\n","def recommend_k_als(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        # Get the cross join of all user-item pairs and score them.\n","        users = train.select(DEFAULT_USER_COL).distinct()\n","        items = train.select(DEFAULT_ITEM_COL).distinct()\n","        user_item = users.crossJoin(items)\n","        dfs_pred = model.transform(user_item)\n","\n","        # Remove seen items\n","        dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n","            train.alias(\"train\"),\n","            (dfs_pred[DEFAULT_USER_COL] == train[DEFAULT_USER_COL])\n","            & (dfs_pred[DEFAULT_ITEM_COL] == train[DEFAULT_ITEM_COL]),\n","            how=\"outer\",\n","        )\n","        topk_scores = dfs_pred_exclude_train.filter(\n","            dfs_pred_exclude_train[\"train.\" + DEFAULT_RATING_COL].isNull()\n","        ).select(\n","            \"pred.\" + DEFAULT_USER_COL,\n","            \"pred.\" + DEFAULT_ITEM_COL,\n","            \"pred.\" + DEFAULT_PREDICTION_COL,\n","        )\n","    return topk_scores, t\n","\n","\n","als_params = {\n","    \"rank\": 10,\n","    \"maxIter\": 20,\n","    \"implicitPrefs\": False,\n","    \"alpha\": 0.1,\n","    \"regParam\": 0.05,\n","    \"coldStartStrategy\": \"drop\",\n","    \"nonnegative\": False,\n","    \"userCol\": DEFAULT_USER_COL,\n","    \"itemCol\": DEFAULT_ITEM_COL,\n","    \"ratingCol\": DEFAULT_RATING_COL,\n","}"],"metadata":{"id":"etb1IkQvs3FU","executionInfo":{"status":"aborted","timestamp":1667642261028,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## NCF"],"metadata":{"id":"M5QhzXoRr0b6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"28jUVetSy9As","executionInfo":{"status":"aborted","timestamp":1667642261028,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["from recommenders.models.ncf.ncf_singlenode import NCF\n","from recommenders.models.ncf.dataset import Dataset as NCFDataset\n","\n","def prepare_training_ncf(df_train, df_test):\n","    #df_train.sort_values([\"userID\"], axis=0, ascending=[True], inplace=True)\n","    #df_test.sort_values([\"userID\"], axis=0, ascending=[True], inplace=True)\n","    train = df_train.sort_values([\"userID\"], axis=0, ascending=[True])\n","    test = df_test.sort_values([\"userID\"], axis=0, ascending=[True])\n","    test = test[df_test[\"userID\"].isin(train[\"userID\"].unique())]\n","    test = test[test[\"itemID\"].isin(train[\"itemID\"].unique())]\n","    train.to_csv(TRAIN_FILE, index=False)\n","    test.to_csv(TEST_FILE, index=False)\n","    return NCFDataset(\n","        train_file=TRAIN_FILE,\n","        col_user=DEFAULT_USER_COL,\n","        col_item=DEFAULT_ITEM_COL,\n","        col_rating=DEFAULT_RATING_COL,\n","        seed=SEED,\n","    )\n","\n","\n","def train_ncf(params, data):\n","    model = NCF(n_users=data.n_users, n_items=data.n_items, **params)\n","    with Timer() as t:\n","        model.fit(data)\n","    return model, t\n","\n","\n","def recommend_k_ncf(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        users, items, preds = [], [], []\n","        item = list(train[DEFAULT_ITEM_COL].unique())\n","        for user in train[DEFAULT_USER_COL].unique():\n","            user = [user] * len(item)\n","            users.extend(user)\n","            items.extend(item)\n","            preds.extend(list(model.predict(user, item, is_list=True)))\n","        topk_scores = pd.DataFrame(\n","            data={\n","                DEFAULT_USER_COL: users,\n","                DEFAULT_ITEM_COL: items,\n","                DEFAULT_PREDICTION_COL: preds,\n","            }\n","        )\n","        merged = pd.merge(\n","            train, topk_scores, on=[DEFAULT_USER_COL, DEFAULT_ITEM_COL], how=\"outer\"\n","        )\n","        topk_scores = merged[merged[DEFAULT_RATING_COL].isnull()].drop(\n","            DEFAULT_RATING_COL, axis=1\n","        )\n","    # Remove temp files\n","    return topk_scores, t\n","\n","ncf_params = {\n","    \"model_type\": \"NeuMF\",\n","    \"n_factors\": 4,\n","    \"layer_sizes\": [16, 8, 4],\n","    \"n_epochs\": 20,\n","    \"batch_size\": 1024,\n","    \"learning_rate\": 1e-3,\n","    \"verbose\": 10\n","}"]},{"cell_type":"markdown","source":["## LightGCN"],"metadata":{"id":"QsJmgwgNsBE8"}},{"cell_type":"code","source":["from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n","from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n","\n","def prepare_training_lightgcn(train, test):\n","    return ImplicitCF(train=train, test=test)\n","\n","def train_lightgcn(params, data):\n","    hparams = prepare_hparams(**params)\n","    model = LightGCN(hparams, data)\n","    with Timer() as t:\n","        model.fit()\n","    return model, t\n","\n","def recommend_k_lightgcn(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        topk_scores = model.recommend_k_items(\n","            test, top_k=top_k, remove_seen=remove_seen\n","        )\n","    return topk_scores, t\n","\n","lightgcn_param = {\n","    \"yaml_file\": os.path.join(\"drive\", \"MyDrive\", \"4222Group9\", \"lightgcn.yaml\"),\n","    \"n_layers\": 3,\n","    \"batch_size\": 1024,\n","    \"epochs\": 1000,\n","    \"learning_rate\": 0.005,\n","    \"eval_epoch\": 10,\n","    \"top_k\": DEFAULT_K,\n","}"],"metadata":{"id":"BZtl_jr3sA1o","executionInfo":{"status":"aborted","timestamp":1667642261028,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KGAT"],"metadata":{"id":"pIDpds_1tSxY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"juTZLU9ktSxZ","executionInfo":{"status":"aborted","timestamp":1667642261029,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":["import os\n","import sys\n","import random\n","from time import time\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from KGAT_folder.KGAT import KGAT\n","from KGAT_folder.log_helper import *\n","from KGAT_folder.parser_kgat import *\n","from KGAT_folder.metrics import *\n","from KGAT_folder.model_helper import *\n","from KGAT_folder.loader_kgat import DataLoaderKGAT\n","\n","\n","def train_kgat():\n","    args = parse_kgat_args()\n","    train(args)\n","    with Timer() as t:\n","      model, data, Ks, device = train(args)\n","    return model, data, Ks, device, t\n","\n","def evaluate_kgat(model, dataloader, Ks, device):\n","    test_batch_size = dataloader.test_batch_size\n","    train_user_dict = dataloader.train_user_dict\n","    test_user_dict = dataloader.test_user_dict\n","\n","    model.eval()\n","\n","    user_ids = list(test_user_dict.keys())\n","    user_ids_batches = [user_ids[i: i + test_batch_size] for i in range(0, len(user_ids), test_batch_size)]\n","    user_ids_batches = [torch.LongTensor(d) for d in user_ids_batches]\n","\n","    n_items = dataloader.n_items\n","    item_ids = torch.arange(n_items, dtype=torch.long).to(device)\n","\n","    cf_scores = []\n","    metric_names = ['precision', 'recall', 'ndcg']\n","    metrics_dict = {k: {m: [] for m in metric_names} for k in Ks}\n","\n","    with tqdm(total=len(user_ids_batches), desc='Evaluating Iteration') as pbar:\n","        for batch_user_ids in user_ids_batches:\n","            batch_user_ids = batch_user_ids.to(device)\n","\n","            with torch.no_grad():\n","                batch_scores = model(batch_user_ids, item_ids, mode='predict')       # (n_batch_users, n_items)\n","\n","            batch_scores = batch_scores.cpu()\n","            batch_metrics = calc_metrics_at_k(batch_scores, train_user_dict, test_user_dict, batch_user_ids.cpu().numpy(), item_ids.cpu().numpy(), Ks)\n","\n","            cf_scores.append(batch_scores.numpy())\n","            for k in Ks:\n","                for m in metric_names:\n","                    metrics_dict[k][m].append(batch_metrics[k][m])\n","            pbar.update(1)\n","\n","    cf_scores = np.concatenate(cf_scores, axis=0)\n","    for k in Ks:\n","        for m in metric_names:\n","            metrics_dict[k][m] = np.concatenate(metrics_dict[k][m]).mean()\n","    return cf_scores, metrics_dict\n","\n","\n","def train(args):\n","    # seed\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.cuda.manual_seed_all(args.seed)\n","\n","    log_save_id = create_log_id(args.save_dir)\n","    logging_config(folder=args.save_dir, name='log{:d}'.format(log_save_id), no_console=False)\n","    logging.info(args)\n","\n","    # GPU / CPU\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # load data\n","    data = DataLoaderKGAT(args, logging)\n","    if args.use_pretrain == 1:\n","        user_pre_embed = torch.tensor(data.user_pre_embed)\n","        item_pre_embed = torch.tensor(data.item_pre_embed)\n","    else:\n","        user_pre_embed, item_pre_embed = None, None\n","\n","    # construct model & optimizer\n","    model = KGAT(args, data.n_users, data.n_entities, data.n_relations, data.A_in, user_pre_embed, item_pre_embed)\n","    if args.use_pretrain == 2:\n","        model = load_model(model, args.pretrain_model_path)\n","\n","    model.to(device)\n","    logging.info(model)\n","\n","    cf_optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","    kg_optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","\n","    # initialize metrics\n","    best_epoch = -1\n","    best_recall = 0\n","\n","    Ks = eval(args.Ks)\n","    k_min = min(Ks)\n","    k_max = max(Ks)\n","\n","    epoch_list = []\n","    metrics_list = {k: {'precision': [], 'recall': [], 'ndcg': []} for k in Ks}\n","\n","    # train model\n","    for epoch in range(1, args.n_epoch + 1):\n","        time0 = time()\n","        model.train()\n","\n","        # train cf\n","        time1 = time()\n","        cf_total_loss = 0\n","        n_cf_batch = data.n_cf_train // data.cf_batch_size + 1\n","\n","        for iter in range(1, n_cf_batch + 1):\n","            time2 = time()\n","            cf_batch_user, cf_batch_pos_item, cf_batch_neg_item = data.generate_cf_batch(data.train_user_dict, data.cf_batch_size)\n","            cf_batch_user = cf_batch_user.to(device)\n","            cf_batch_pos_item = cf_batch_pos_item.to(device)\n","            cf_batch_neg_item = cf_batch_neg_item.to(device)\n","\n","            cf_batch_loss = model(cf_batch_user, cf_batch_pos_item, cf_batch_neg_item, mode='train_cf')\n","\n","            if np.isnan(cf_batch_loss.cpu().detach().numpy()):\n","                logging.info('ERROR (CF Training): Epoch {:04d} Iter {:04d} / {:04d} Loss is nan.'.format(epoch, iter, n_cf_batch))\n","                sys.exit()\n","\n","            cf_batch_loss.backward()\n","            cf_optimizer.step()\n","            cf_optimizer.zero_grad()\n","            cf_total_loss += cf_batch_loss.item()\n","\n","            if (iter % args.cf_print_every) == 0:\n","                logging.info('CF Training: Epoch {:04d} Iter {:04d} / {:04d} | Time {:.1f}s | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(epoch, iter, n_cf_batch, time() - time2, cf_batch_loss.item(), cf_total_loss / iter))\n","        logging.info('CF Training: Epoch {:04d} Total Iter {:04d} | Total Time {:.1f}s | Iter Mean Loss {:.4f}'.format(epoch, n_cf_batch, time() - time1, cf_total_loss / n_cf_batch))\n","\n","        # train kg\n","        time3 = time()\n","        kg_total_loss = 0\n","        n_kg_batch = data.n_kg_train // data.kg_batch_size + 1\n","\n","        for iter in range(1, n_kg_batch + 1):\n","            time4 = time()\n","            kg_batch_head, kg_batch_relation, kg_batch_pos_tail, kg_batch_neg_tail = data.generate_kg_batch(data.train_kg_dict, data.kg_batch_size, data.n_users_entities)\n","            kg_batch_head = kg_batch_head.to(device)\n","            kg_batch_relation = kg_batch_relation.to(device)\n","            kg_batch_pos_tail = kg_batch_pos_tail.to(device)\n","            kg_batch_neg_tail = kg_batch_neg_tail.to(device)\n","\n","            kg_batch_loss = model(kg_batch_head, kg_batch_relation, kg_batch_pos_tail, kg_batch_neg_tail, mode='train_kg')\n","\n","            if np.isnan(kg_batch_loss.cpu().detach().numpy()):\n","                logging.info('ERROR (KG Training): Epoch {:04d} Iter {:04d} / {:04d} Loss is nan.'.format(epoch, iter, n_kg_batch))\n","                sys.exit()\n","\n","            kg_batch_loss.backward()\n","            kg_optimizer.step()\n","            kg_optimizer.zero_grad()\n","            kg_total_loss += kg_batch_loss.item()\n","\n","            if (iter % args.kg_print_every) == 0:\n","                logging.info('KG Training: Epoch {:04d} Iter {:04d} / {:04d} | Time {:.1f}s | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(epoch, iter, n_kg_batch, time() - time4, kg_batch_loss.item(), kg_total_loss / iter))\n","        logging.info('KG Training: Epoch {:04d} Total Iter {:04d} | Total Time {:.1f}s | Iter Mean Loss {:.4f}'.format(epoch, n_kg_batch, time() - time3, kg_total_loss / n_kg_batch))\n","\n","        # update attention\n","        time5 = time()\n","        h_list = data.h_list.to(device)\n","        t_list = data.t_list.to(device)\n","        r_list = data.r_list.to(device)\n","        relations = list(data.laplacian_dict.keys())\n","        model(h_list, t_list, r_list, relations, mode='update_att')\n","        logging.info('Update Attention: Epoch {:04d} | Total Time {:.1f}s'.format(epoch, time() - time5))\n","\n","        logging.info('CF + KG Training: Epoch {:04d} | Total Time {:.1f}s'.format(epoch, time() - time0))\n","    return model, data, Ks, device\n"]},{"cell_type":"markdown","source":["## Comparison"],"metadata":{"id":"W8cmNmNcsIrU"}},{"cell_type":"code","source":["params = {\n","    \"als\": als_params,\n","    \"ncf\": ncf_params,\n","    \"lightgcn\": lightgcn_param,\n","}\n","prepare_training_data = {\n","    \"als\": prepare_training_als,\n","    \"ncf\": prepare_training_ncf,\n","    \"lightgcn\": prepare_training_lightgcn,\n","}\n","\n","\n","from recommenders.evaluation.spark_evaluation import (\n","    SparkRatingEvaluation,\n","    SparkRankingEvaluation,\n",")\n","def rating_metrics_pyspark(test, predictions):\n","    rating_eval = SparkRatingEvaluation(test, predictions, **COL_DICT)\n","    return {\n","        \"RMSE\": rating_eval.rmse(),\n","        \"MAE\": rating_eval.mae(),\n","        \"R2\": rating_eval.exp_var(),\n","        \"Explained Variance\": rating_eval.rsquared(),\n","    }\n","def ranking_metrics_pyspark(test, predictions, k=DEFAULT_K):\n","    rank_eval = SparkRankingEvaluation(\n","        test, predictions, k=k, relevancy_method=\"top_k\", **COL_DICT\n","    )\n","    return {\n","        \"MAP\": rank_eval.map_at_k(),\n","        \"nDCG@k\": rank_eval.ndcg_at_k(),\n","        \"Precision@k\": rank_eval.precision_at_k(),\n","        \"Recall@k\": rank_eval.recall_at_k(),\n","    }\n","\n","prepare_metrics_data = {\n","    \"als\": lambda train, test: prepare_metrics_als(train, test),\n","}"],"metadata":{"id":"WDnMUwTkmaVl","executionInfo":{"status":"aborted","timestamp":1667642261029,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8b6_iXtyy67r"},"source":["# 5 Training and Inspecting"]},{"cell_type":"code","source":["trainer = {\n","    \"als\": lambda params, data: train_als(params, data),\n","    \"ncf\": lambda params, data: train_ncf(params, data),\n","    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n","}\n","rating_predictor = {\n","    \"als\": lambda model, test: predict_als(model, test),\n","}\n","rating_evaluator = {\n","    \"als\": lambda test, predictions: rating_metrics_pyspark(test, predictions)\n","}\n","ranking_predictor = {\n","    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n","    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n","    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n","}\n","ranking_evaluator = {\n","    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n","    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n","    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n","}"],"metadata":{"id":"E1xrvyOJm_Jw","executionInfo":{"status":"aborted","timestamp":1667642261030,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics = {\n","    \"als\": [\"rating\", \"ranking\"],\n","    \"ncf\": [\"ranking\"],\n","    \"lightgcn\": [\"ranking\"]\n","}"],"metadata":{"id":"5yA5KwbOpFKV","executionInfo":{"status":"aborted","timestamp":1667642261030,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_summary(data, algo, k, train_time, time_rating, rating_metrics, time_ranking, ranking_metrics):\n","    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": time_rating, \"Recommending time (s)\": time_ranking}\n","    if rating_metrics is None:\n","        rating_metrics = {\n","            \"RMSE\": np.nan,\n","            \"MAE\": np.nan,\n","            \"R2\": np.nan,\n","            \"Explained Variance\": np.nan,\n","        }\n","    if ranking_metrics is None:\n","        ranking_metrics = {\n","            \"MAP\": np.nan,\n","            \"nDCG@k\": np.nan,\n","            \"Precision@k\": np.nan,\n","            \"Recall@k\": np.nan,\n","        }\n","    summary.update(rating_metrics)\n","    summary.update(ranking_metrics)\n","    return summary"],"metadata":{"id":"QiSBW662nROl","executionInfo":{"status":"aborted","timestamp":1667642261030,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_sizes = [\"100k\"] # Movielens data size: 100k, 1m, 10m, or 20m\n","#algorithms = [ \"lightgcn\"]\n","algorithms = [\"als\", \"ncf\", \"lightgcn\", \"kgat\"]"],"metadata":{"id":"8reKYmEH2d-k","executionInfo":{"status":"aborted","timestamp":1667642261031,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","# For each data size and each algorithm, a recommender is evaluated. \n","cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n","df_results = pd.DataFrame(columns=cols)\n","\n","for data_size in data_sizes:\n","    # Load the dataset\n","    df = movielens.load_pandas_df(\n","        size=data_size,\n","        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n","    )\n","    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n","    \n","    # Split the dataset\n","    df_train, df_test = python_stratified_split(df,\n","                                                ratio=0.75, \n","                                                min_rating=1, \n","                                                filter_by=\"item\", \n","                                                col_user=DEFAULT_USER_COL, \n","                                                col_item=DEFAULT_ITEM_COL\n","                                                )\n","   \n","    # Loop through the algos\n","    for algo in algorithms:\n","      print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n","      if algo == 'kgat':\n","        model, data, Ks, device, time_train = train_kgat()\n","        _, metrics_dict_kgat = evaluate_kgat(model, data, Ks, device)\n","        print(metrics_dict_kgat)\n","        # Record results\n","        #summary = generate_summary('100k', algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","        #df_results.loc[df_results.shape[0] + 1] = summary\n","        \n","      else:\n","        # Data prep for training set\n","        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","        \n","        # Get model parameters\n","        model_params = params[algo]\n","          \n","        # Train the model\n","        model, time_train = trainer[algo](model_params, train)\n","        print(f\"Training time: {time_train}s\")\n","                \n","        # Predict and evaluate\n","        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","        \n","        if \"rating\" in metrics[algo]:   \n","            # Predict for rating\n","            preds, time_rating = rating_predictor[algo](model, test)\n","            print(f\"Rating prediction time: {time_rating}s\")\n","            \n","            # Evaluate for rating\n","            ratings = rating_evaluator[algo](test, preds)\n","        else:\n","            ratings = None\n","            time_rating = np.nan\n","        \n","        if \"ranking\" in metrics[algo]:\n","            # Predict for ranking\n","            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n","            print(f\"Ranking prediction time: {time_ranking}s\")\n","            \n","            # Evaluate for rating\n","            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n","        else:\n","            rankings = None\n","            time_ranking = np.nan\n","            \n","        # Record results\n","        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","        df_results.loc[df_results.shape[0] + 1] = summary\n","        \n","print(\"\\nComputation finished\")"],"metadata":{"id":"-17fyWdVmiHM","executionInfo":{"status":"aborted","timestamp":1667642261031,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_results"],"metadata":{"id":"36QRfkqVrYzi","executionInfo":{"status":"aborted","timestamp":1667642261031,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3B4ScYiXzCN1"},"source":["# 6 Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pj0dLoWAzDoh","executionInfo":{"status":"aborted","timestamp":1667642261031,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"seUWygXTzYfc"},"source":["# 7 Credit and Reference\n","\n","1. https://github.com/microsoft/recommenders"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('TFmacOS')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"90fff557ab5125bf18e450eefdf7065daeca14691b1decf231ada582ea64d91c"}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}