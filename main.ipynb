{"cells":[{"cell_type":"markdown","metadata":{"id":"vobP7ahXP1EG"},"source":["# Graph-Learning-Based Recommender System on MovieLens\n","\n","### Group 9\n","\n","- AGARWAL, Sahil\n","- WEI, Yuanjing\n","- ZHANG, Yujun yzhanglo@connect.ust.hk\n","\n","Group project of COMP4222@HKUST in 2022 Fall."]},{"cell_type":"markdown","metadata":{"id":"QpTqYz7qYJbP"},"source":["# 1 Environment Configuration"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":603},"executionInfo":{"elapsed":30299,"status":"error","timestamp":1667642237984,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"MXxR7IpwI83o","outputId":"9933f848-12fa-442f-afe4-0d95a20a464e","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["/data/yzhanglo/4222project\n","backup_main.ipynb  \u001b[0m\u001b[38;5;27mLightGCN\u001b[0m/      \u001b[38;5;27mml-latest-small\u001b[0m/  requirements.txt\n","\u001b[38;5;27mcomp4222\u001b[0m/          lightgcn.yaml  movielens.ipynb\n","\u001b[38;5;27mKGAT_folder\u001b[0m/       main.ipynb     \u001b[38;5;9mmovielens.zip\u001b[0m\n","LICENSE            \u001b[38;5;27mml-100k\u001b[0m/       \u001b[38;5;27mrecommenders\u001b[0m/\n"]}],"source":["# change the path in the following\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd '/content/drive/MyDrive/4222Group9'\n","except:\n","    %cd '/data/yzhanglo/4222project'\n","\n","import comp4222\n","import recommenders\n","%pwd\n","%ls"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1667642237987,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"7RuvfqktV-jm","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-21 12:14:55.857302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","/data/yzhanglo/miniconda/envs/cu101/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import torch\n","from tensorboardX import SummaryWriter\n","\n","# easier to print by putting variable as a single line\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","# make matplotlib figures appear inline in the notebook rather than in a new window.\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# Add some convenience functions to Pandas DataFrame.\n","pd.options.display.max_rows = 10\n","pd.options.display.float_format = '{:.2f}'.format\n","def mask(df, key, function):\n","  \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n","  return df[function(df[key])]\n","\n","def flatten_cols(df):\n","  df.columns = [' '.join(col).strip() for col in df.columns.values]\n","  return df\n","\n","pd.DataFrame.mask = mask\n","pd.DataFrame.flatten_cols = flatten_cols\n","\n","# http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1667642237988,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"zLFdbrlyOWiT","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["hahaha\n"]}],"source":["# Testing the module functionality\n","from comp4222 import b\n","comp4222.b.ok()"]},{"cell_type":"markdown","metadata":{"id":"dkgjzCmnWXUw"},"source":["# 2 MovieLens\n"]},{"cell_type":"markdown","metadata":{"id":"Mq_PrL0LZrGa"},"source":["We're using ml-100k from MovieLens. It contains 100000 ratings from 943 users on 1682 movies. Each user has rated at least 20 movies. And the data was collected during the seven-month period from September 19th, 1997 through April 22nd, 1998. The readme.md is avaliable [here](https://files.grouplens.org/datasets/movielens/ml-100k-README.txt).\n","\n","P.s. As for now, we're using the provided code for dataset loading defined by lightgcn and microsoft recommender repository."]},{"cell_type":"markdown","metadata":{"id":"g_XRmlt-yMUu"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1667642237989,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"Vt7THxaKWZDv","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["('movielens.zip', <http.client.HTTPMessage at 0x7f9c580a4f40>)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Download MovieLens data.\n","dataset_name = \"ml-latest-small\"\n","from urllib.request import urlretrieve\n","import zipfile\n","urlretrieve(f\"https://files.grouplens.org/datasets/movielens/{dataset_name}.zip\", \"movielens.zip\")\n","zipfile.ZipFile(\"movielens.zip\", \"r\").extractall()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1667642237989,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"vhrmXmjSh5jf","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movieId</th>\n","      <th>title</th>\n","      <th>genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story (1995)</td>\n","      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji (1995)</td>\n","      <td>Adventure|Children|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men (1995)</td>\n","      <td>Comedy|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale (1995)</td>\n","      <td>Comedy|Drama|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II (1995)</td>\n","      <td>Comedy</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9737</th>\n","      <td>193581</td>\n","      <td>Black Butler: Book of the Atlantic (2017)</td>\n","      <td>Action|Animation|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>9738</th>\n","      <td>193583</td>\n","      <td>No Game No Life: Zero (2017)</td>\n","      <td>Animation|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>9739</th>\n","      <td>193585</td>\n","      <td>Flint (2017)</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>9740</th>\n","      <td>193587</td>\n","      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n","      <td>Action|Animation</td>\n","    </tr>\n","    <tr>\n","      <th>9741</th>\n","      <td>193609</td>\n","      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n","      <td>Comedy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9742 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["      movieId                                      title  \\\n","0           1                           Toy Story (1995)   \n","1           2                             Jumanji (1995)   \n","2           3                    Grumpier Old Men (1995)   \n","3           4                   Waiting to Exhale (1995)   \n","4           5         Father of the Bride Part II (1995)   \n","...       ...                                        ...   \n","9737   193581  Black Butler: Book of the Atlantic (2017)   \n","9738   193583               No Game No Life: Zero (2017)   \n","9739   193585                               Flint (2017)   \n","9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n","9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n","\n","                                           genres  \n","0     Adventure|Animation|Children|Comedy|Fantasy  \n","1                      Adventure|Children|Fantasy  \n","2                                  Comedy|Romance  \n","3                            Comedy|Drama|Romance  \n","4                                          Comedy  \n","...                                           ...  \n","9737              Action|Animation|Comedy|Fantasy  \n","9738                     Animation|Comedy|Fantasy  \n","9739                                        Drama  \n","9740                             Action|Animation  \n","9741                                       Comedy  \n","\n","[9742 rows x 3 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["movies = pd.read_csv(f\"{dataset_name}/movies.csv\")\n","genre_cols = [\n","    \"(no genres listed)\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n","    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n","    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n","]\n","movies"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1667642237990,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"HipV8C2ziAUh","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>tag</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>60756</td>\n","      <td>funny</td>\n","      <td>1445714994</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>60756</td>\n","      <td>Highly quotable</td>\n","      <td>1445714996</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>60756</td>\n","      <td>will ferrell</td>\n","      <td>1445714992</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>89774</td>\n","      <td>Boxing story</td>\n","      <td>1445715207</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>89774</td>\n","      <td>MMA</td>\n","      <td>1445715200</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3678</th>\n","      <td>606</td>\n","      <td>7382</td>\n","      <td>for katie</td>\n","      <td>1171234019</td>\n","    </tr>\n","    <tr>\n","      <th>3679</th>\n","      <td>606</td>\n","      <td>7936</td>\n","      <td>austere</td>\n","      <td>1173392334</td>\n","    </tr>\n","    <tr>\n","      <th>3680</th>\n","      <td>610</td>\n","      <td>3265</td>\n","      <td>gun fu</td>\n","      <td>1493843984</td>\n","    </tr>\n","    <tr>\n","      <th>3681</th>\n","      <td>610</td>\n","      <td>3265</td>\n","      <td>heroic bloodshed</td>\n","      <td>1493843978</td>\n","    </tr>\n","    <tr>\n","      <th>3682</th>\n","      <td>610</td>\n","      <td>168248</td>\n","      <td>Heroic Bloodshed</td>\n","      <td>1493844270</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3683 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["      userId  movieId               tag   timestamp\n","0          2    60756             funny  1445714994\n","1          2    60756   Highly quotable  1445714996\n","2          2    60756      will ferrell  1445714992\n","3          2    89774      Boxing story  1445715207\n","4          2    89774               MMA  1445715200\n","...      ...      ...               ...         ...\n","3678     606     7382         for katie  1171234019\n","3679     606     7936           austere  1173392334\n","3680     610     3265            gun fu  1493843984\n","3681     610     3265  heroic bloodshed  1493843978\n","3682     610   168248  Heroic Bloodshed  1493844270\n","\n","[3683 rows x 4 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["tags = pd.read_csv(f\"{dataset_name}/tags.csv\")\n","tags"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1667642237990,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"RF0KOsiadLM1","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4.00</td>\n","      <td>964982703</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4.00</td>\n","      <td>964981247</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>4.00</td>\n","      <td>964982224</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>5.00</td>\n","      <td>964983815</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>5.00</td>\n","      <td>964982931</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>100831</th>\n","      <td>610</td>\n","      <td>166534</td>\n","      <td>4.00</td>\n","      <td>1493848402</td>\n","    </tr>\n","    <tr>\n","      <th>100832</th>\n","      <td>610</td>\n","      <td>168248</td>\n","      <td>5.00</td>\n","      <td>1493850091</td>\n","    </tr>\n","    <tr>\n","      <th>100833</th>\n","      <td>610</td>\n","      <td>168250</td>\n","      <td>5.00</td>\n","      <td>1494273047</td>\n","    </tr>\n","    <tr>\n","      <th>100834</th>\n","      <td>610</td>\n","      <td>168252</td>\n","      <td>5.00</td>\n","      <td>1493846352</td>\n","    </tr>\n","    <tr>\n","      <th>100835</th>\n","      <td>610</td>\n","      <td>170875</td>\n","      <td>3.00</td>\n","      <td>1493846415</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100836 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["        userId  movieId  rating   timestamp\n","0            1        1    4.00   964982703\n","1            1        3    4.00   964981247\n","2            1        6    4.00   964982224\n","3            1       47    5.00   964983815\n","4            1       50    5.00   964982931\n","...        ...      ...     ...         ...\n","100831     610   166534    4.00  1493848402\n","100832     610   168248    5.00  1493850091\n","100833     610   168250    5.00  1494273047\n","100834     610   168252    5.00  1493846352\n","100835     610   170875    3.00  1493846415\n","\n","[100836 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["ratings = pd.read_csv(f\"{dataset_name}/ratings.csv\")\n","ratings"]},{"cell_type":"markdown","metadata":{"id":"giSgiu7jyO04"},"source":["## Data Exploration"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1667642237991,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"i5tJTHDFXmd7","vscode":{"languageId":"python"}},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'altair'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#%pip install altair\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maltair\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m alt\u001b[38;5;241m.\u001b[39mdata_transformers\u001b[38;5;241m.\u001b[39menable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, max_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m alt\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39menable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolab\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'altair'"]}],"source":["#%pip install altair\n","import altair as alt\n","alt.data_transformers.enable('default', max_rows=None)\n","alt.renderers.enable('colab')"]},{"cell_type":"markdown","metadata":{"id":"yIDqnYvByqGx"},"source":["# 3 Preliminaries\n","\n","There's no much symbol to be defined at this stage."]},{"cell_type":"markdown","metadata":{"id":"OzxFHwzLy2vU"},"source":["# 4 Models Definition"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"elapsed":473,"status":"error","timestamp":1667642260421,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"U0Q4UEcMy6g6","outputId":"62577a20-91f8-43cf-8ea8-5d9138fa711a","vscode":{"languageId":"python"}},"outputs":[],"source":["from recommenders.utils.timer import Timer\n","from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n","from recommenders.utils.constants import (\n","COL_DICT,\n","    DEFAULT_K,\n","    DEFAULT_USER_COL,\n","    DEFAULT_ITEM_COL,\n","    DEFAULT_RATING_COL,\n","    DEFAULT_PREDICTION_COL,\n","    DEFAULT_TIMESTAMP_COL,\n","    SEED,\n",")\n","\n","# Helpers\n","import os\n","from tempfile import TemporaryDirectory\n","tmp_dir = TemporaryDirectory()\n","TRAIN_FILE = os.path.join(tmp_dir.name, \"df_train.csv\")\n","TEST_FILE = os.path.join(tmp_dir.name, \"df_test.csv\")\n","\n","from recommenders.evaluation.python_evaluation import (\n","    map_at_k,\n","    ndcg_at_k,\n","    precision_at_k,\n","    recall_at_k,\n",")\n","def ranking_metrics_python(test, predictions, k=DEFAULT_K):\n","    return {\n","        \"MAP\": map_at_k(test, predictions, k=k, **COL_DICT),\n","        \"nDCG@k\": ndcg_at_k(test, predictions, k=k, **COL_DICT),\n","        \"Precision@k\": precision_at_k(test, predictions, k=k, **COL_DICT),\n","        \"Recall@k\": recall_at_k(test, predictions, k=k, **COL_DICT),\n","    }\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"elapsed":6,"status":"error","timestamp":1667642261027,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"kBSE8h2MzB16","outputId":"cfd4e3c0-5af3-4a2d-f1ea-dddfcadbd897","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["22/11/21 12:15:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]},{"data":{"text/plain":["<torch._C.Generator at 0x7f9b7f2f1370>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["from recommenders.utils.spark_utils import start_or_get_spark\n","spark = start_or_get_spark(\"PySpark\", memory=\"32g\")\n","spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n","\n","from recommenders.datasets import movielens\n","from recommenders.datasets.python_splitters import python_stratified_split\n","import os\n","\n","# fix random seeds to make sure out runs are reproducible\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)"]},{"cell_type":"markdown","metadata":{"id":"3ik1fSYis21e"},"source":["## ALS"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1667642261028,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"etb1IkQvs3FU","vscode":{"languageId":"python"}},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField\n","from pyspark.sql.types import FloatType, IntegerType, LongType\n","from pyspark.ml.recommendation import ALS\n","\n","\n","def prepare_training_als(train, test):\n","    schema = StructType(\n","        (\n","            StructField(DEFAULT_USER_COL, IntegerType()),\n","            StructField(DEFAULT_ITEM_COL, IntegerType()),\n","            StructField(DEFAULT_RATING_COL, FloatType()),\n","            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n","        )\n","    )\n","    spark = start_or_get_spark()\n","    return spark.createDataFrame(train, schema).cache()\n","\n","def prepare_metrics_als(train, test):\n","    schema = StructType(\n","        (\n","            StructField(DEFAULT_USER_COL, IntegerType()),\n","            StructField(DEFAULT_ITEM_COL, IntegerType()),\n","            StructField(DEFAULT_RATING_COL, FloatType()),\n","            StructField(DEFAULT_TIMESTAMP_COL, LongType()),\n","        )\n","    )\n","    spark = start_or_get_spark()\n","    return spark.createDataFrame(train, schema).cache(), spark.createDataFrame(test, schema).cache()\n","\n","def predict_als(model, test):\n","    with Timer() as t:\n","        preds = model.transform(test)\n","    return preds, t\n","\n","def train_als(params, data):\n","    symbol = ALS(**params)\n","    with Timer() as t:\n","        model = symbol.fit(data)\n","    return model, t\n","\n","def recommend_k_als(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        # Get the cross join of all user-item pairs and score them.\n","        users = train.select(DEFAULT_USER_COL).distinct()\n","        items = train.select(DEFAULT_ITEM_COL).distinct()\n","        user_item = users.crossJoin(items)\n","        dfs_pred = model.transform(user_item)\n","\n","        # Remove seen items\n","        dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n","            train.alias(\"train\"),\n","            (dfs_pred[DEFAULT_USER_COL] == train[DEFAULT_USER_COL])\n","            & (dfs_pred[DEFAULT_ITEM_COL] == train[DEFAULT_ITEM_COL]),\n","            how=\"outer\",\n","        )\n","        topk_scores = dfs_pred_exclude_train.filter(\n","            dfs_pred_exclude_train[\"train.\" + DEFAULT_RATING_COL].isNull()\n","        ).select(\n","            \"pred.\" + DEFAULT_USER_COL,\n","            \"pred.\" + DEFAULT_ITEM_COL,\n","            \"pred.\" + DEFAULT_PREDICTION_COL,\n","        )\n","    return topk_scores, t\n","\n","\n","als_params = {\n","    \"rank\": 10,\n","    \"maxIter\": 20,\n","    \"implicitPrefs\": False,\n","    \"alpha\": 0.1,\n","    \"regParam\": 0.05,\n","    \"coldStartStrategy\": \"drop\",\n","    \"nonnegative\": False,\n","    \"userCol\": DEFAULT_USER_COL,\n","    \"itemCol\": DEFAULT_ITEM_COL,\n","    \"ratingCol\": DEFAULT_RATING_COL,\n","}"]},{"cell_type":"markdown","metadata":{"id":"M5QhzXoRr0b6"},"source":["## NCF"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1667642261028,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"28jUVetSy9As","vscode":{"languageId":"python"}},"outputs":[],"source":["from recommenders.models.ncf.ncf_singlenode import NCF\n","from recommenders.models.ncf.dataset import Dataset as NCFDataset\n","\n","def prepare_training_ncf(df_train, df_test):\n","    #df_train.sort_values([\"userID\"], axis=0, ascending=[True], inplace=True)\n","    #df_test.sort_values([\"userID\"], axis=0, ascending=[True], inplace=True)\n","    train = df_train.sort_values([\"userID\"], axis=0, ascending=[True])\n","    test = df_test.sort_values([\"userID\"], axis=0, ascending=[True])\n","    test = test[df_test[\"userID\"].isin(train[\"userID\"].unique())]\n","    test = test[test[\"itemID\"].isin(train[\"itemID\"].unique())]\n","    train.to_csv(TRAIN_FILE, index=False)\n","    test.to_csv(TEST_FILE, index=False)\n","    return NCFDataset(\n","        train_file=TRAIN_FILE,\n","        col_user=DEFAULT_USER_COL,\n","        col_item=DEFAULT_ITEM_COL,\n","        col_rating=DEFAULT_RATING_COL,\n","        seed=SEED,\n","    )\n","\n","\n","def train_ncf(params, data):\n","    model = NCF(n_users=data.n_users, n_items=data.n_items, **params)\n","    with Timer() as t:\n","        model.fit(data)\n","    return model, t\n","\n","\n","def recommend_k_ncf(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        users, items, preds = [], [], []\n","        item = list(train[DEFAULT_ITEM_COL].unique())\n","        for user in train[DEFAULT_USER_COL].unique():\n","            user = [user] * len(item)\n","            users.extend(user)\n","            items.extend(item)\n","            preds.extend(list(model.predict(user, item, is_list=True)))\n","        topk_scores = pd.DataFrame(\n","            data={\n","                DEFAULT_USER_COL: users,\n","                DEFAULT_ITEM_COL: items,\n","                DEFAULT_PREDICTION_COL: preds,\n","            }\n","        )\n","        merged = pd.merge(\n","            train, topk_scores, on=[DEFAULT_USER_COL, DEFAULT_ITEM_COL], how=\"outer\"\n","        )\n","        topk_scores = merged[merged[DEFAULT_RATING_COL].isnull()].drop(\n","            DEFAULT_RATING_COL, axis=1\n","        )\n","    # Remove temp files\n","    return topk_scores, t\n","\n","ncf_params = {\n","    \"model_type\": \"NeuMF\",\n","    \"n_factors\": 4,\n","    \"layer_sizes\": [16, 8, 4],\n","    \"n_epochs\": 20,\n","    \"batch_size\": 1024,\n","    \"learning_rate\": 1e-3,\n","    \"verbose\": 10\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"pIDpds_1tSxY"},"source":["## KGAT"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1667642261029,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"juTZLU9ktSxZ","vscode":{"languageId":"python"}},"outputs":[],"source":["#%pip install easydict\n","import os\n","import sys\n","import random\n","from time import time\n","\n","import pandas as pd\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from KGAT_folder.KGAT import KGAT\n","from KGAT_folder.log_helper import *\n","from KGAT_folder.parser_kgat import *\n","from KGAT_folder.metrics import *\n","from KGAT_folder.model_helper import *\n","from KGAT_folder.loader_kgat import DataLoaderKGAT\n","\n","\n","def train_kgat():\n","    args = parse_kgat_args()\n","    #train(args)\n","    time0 = time()\n","    model, data, Ks, device = train(args)\n","    time1 = time()\n","    t = time1-time0\n","    return model, data, Ks, device, t\n","\n","def evaluate_kgat(model, dataloader, Ks, device):\n","    test_batch_size = dataloader.test_batch_size\n","    train_user_dict = dataloader.train_user_dict\n","    test_user_dict = dataloader.test_user_dict\n","\n","    model.eval()\n","\n","    user_ids = list(test_user_dict.keys())\n","    user_ids_batches = [user_ids[i: i + test_batch_size] for i in range(0, len(user_ids), test_batch_size)]\n","    user_ids_batches = [torch.LongTensor(d) for d in user_ids_batches]\n","\n","    n_items = dataloader.n_items\n","    item_ids = torch.arange(n_items, dtype=torch.long).to(device)\n","\n","    cf_scores = []\n","    metric_names = ['precision', 'recall', 'ndcg']\n","    metrics_dict = {k: {m: [] for m in metric_names} for k in Ks}\n","\n","    with tqdm(total=len(user_ids_batches), desc='Evaluating Iteration') as pbar:\n","        for batch_user_ids in user_ids_batches:\n","            batch_user_ids = batch_user_ids.to(device)\n","\n","            with torch.no_grad():\n","                batch_scores = model(batch_user_ids, item_ids, mode='predict')       # (n_batch_users, n_items)\n","\n","            batch_scores = batch_scores.cpu()\n","            batch_metrics = calc_metrics_at_k(batch_scores, train_user_dict, test_user_dict, batch_user_ids.cpu().numpy(), item_ids.cpu().numpy(), Ks)\n","\n","            cf_scores.append(batch_scores.numpy())\n","            for k in Ks:\n","                for m in metric_names:\n","                    metrics_dict[k][m].append(batch_metrics[k][m])\n","            pbar.update(1)\n","\n","    cf_scores = np.concatenate(cf_scores, axis=0)\n","    for k in Ks:\n","        for m in metric_names:\n","            metrics_dict[k][m] = np.concatenate(metrics_dict[k][m]).mean()\n","    return cf_scores, metrics_dict\n","\n","\n","def train(args):\n","    # seed\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.cuda.manual_seed_all(args.seed)\n","\n","    #log_save_id = create_log_id(args.save_dir)\n","    #logging_config(folder=args.save_dir, name='log{:d}'.format(log_save_id), no_console=False)\n","    #logging.info(args)\n","\n","    # GPU / CPU\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # load data\n","    data = DataLoaderKGAT(args, logging)\n","    if args.use_pretrain == 1:\n","        user_pre_embed = torch.tensor(data.user_pre_embed)\n","        item_pre_embed = torch.tensor(data.item_pre_embed)\n","    else:\n","        user_pre_embed, item_pre_embed = None, None\n","\n","    # construct model & optimizer\n","    model = KGAT(args, data.n_users, data.n_entities, data.n_relations, data.A_in, user_pre_embed, item_pre_embed)\n","    #if args.use_pretrain == 2:\n","    #    model = load_model(model, args.pretrain_model_path)\n","\n","    model.to(device)\n","    #logging.info(model)\n","\n","    cf_optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","    kg_optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","\n","    # initialize metrics\n","    best_epoch = -1\n","    best_recall = 0\n","\n","    Ks = eval(args.Ks)\n","    k_min = min(Ks)\n","    k_max = max(Ks)\n","\n","    epoch_list = []\n","    metrics_list = {k: {'precision': [], 'recall': [], 'ndcg': []} for k in Ks}\n","\n","    # train model\n","    for epoch in range(1, args.n_epoch + 1):\n","        time0 = time()\n","        model.train()\n","\n","        # train cf\n","        time1 = time()\n","        cf_total_loss = 0\n","        n_cf_batch = data.n_cf_train // data.cf_batch_size + 1\n","\n","        for iter in range(1, n_cf_batch + 1):\n","            time2 = time()\n","            cf_batch_user, cf_batch_pos_item, cf_batch_neg_item = data.generate_cf_batch(data.train_user_dict, data.cf_batch_size)\n","            cf_batch_user = cf_batch_user.to(device)\n","            cf_batch_pos_item = cf_batch_pos_item.to(device)\n","            cf_batch_neg_item = cf_batch_neg_item.to(device)\n","\n","            cf_batch_loss = model(cf_batch_user, cf_batch_pos_item, cf_batch_neg_item, mode='train_cf')\n","\n","            if np.isnan(cf_batch_loss.cpu().detach().numpy()):\n","                logging.info('ERROR (CF Training): Epoch {:04d} Iter {:04d} / {:04d} Loss is nan.'.format(epoch, iter, n_cf_batch))\n","                sys.exit()\n","\n","            cf_batch_loss.backward()\n","            cf_optimizer.step()\n","            cf_optimizer.zero_grad()\n","            cf_total_loss += cf_batch_loss.item()\n","\n","            if (iter % args.cf_print_every) == 0:\n","                logging.info('CF Training: Epoch {:04d} Iter {:04d} / {:04d} | Time {:.1f}s | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(epoch, iter, n_cf_batch, time() - time2, cf_batch_loss.item(), cf_total_loss / iter))\n","        logging.info('CF Training: Epoch {:04d} Total Iter {:04d} | Total Time {:.1f}s | Iter Mean Loss {:.4f}'.format(epoch, n_cf_batch, time() - time1, cf_total_loss / n_cf_batch))\n","\n","        # train kg\n","        time3 = time()\n","        kg_total_loss = 0\n","        n_kg_batch = data.n_kg_train // data.kg_batch_size + 1\n","\n","        for iter in range(1, n_kg_batch + 1):\n","            time4 = time()\n","            kg_batch_head, kg_batch_relation, kg_batch_pos_tail, kg_batch_neg_tail = data.generate_kg_batch(data.train_kg_dict, data.kg_batch_size, data.n_users_entities)\n","            kg_batch_head = kg_batch_head.to(device)\n","            kg_batch_relation = kg_batch_relation.to(device)\n","            kg_batch_pos_tail = kg_batch_pos_tail.to(device)\n","            kg_batch_neg_tail = kg_batch_neg_tail.to(device)\n","\n","            kg_batch_loss = model(kg_batch_head, kg_batch_relation, kg_batch_pos_tail, kg_batch_neg_tail, mode='train_kg')\n","\n","            if np.isnan(kg_batch_loss.cpu().detach().numpy()):\n","                logging.info('ERROR (KG Training): Epoch {:04d} Iter {:04d} / {:04d} Loss is nan.'.format(epoch, iter, n_kg_batch))\n","                sys.exit()\n","\n","            kg_batch_loss.backward()\n","            kg_optimizer.step()\n","            kg_optimizer.zero_grad()\n","            kg_total_loss += kg_batch_loss.item()\n","\n","            if (iter % args.kg_print_every) == 0:\n","                logging.info('KG Training: Epoch {:04d} Iter {:04d} / {:04d} | Time {:.1f}s | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(epoch, iter, n_kg_batch, time() - time4, kg_batch_loss.item(), kg_total_loss / iter))\n","        logging.info('KG Training: Epoch {:04d} Total Iter {:04d} | Total Time {:.1f}s | Iter Mean Loss {:.4f}'.format(epoch, n_kg_batch, time() - time3, kg_total_loss / n_kg_batch))\n","\n","        # update attention\n","        time5 = time()\n","        h_list = data.h_list.to(device)\n","        t_list = data.t_list.to(device)\n","        r_list = data.r_list.to(device)\n","        relations = list(data.laplacian_dict.keys())\n","        model(h_list, t_list, r_list, relations, mode='update_att')\n","        logging.info('Update Attention: Epoch {:04d} | Total Time {:.1f}s'.format(epoch, time() - time5))\n","\n","        logging.info('CF + KG Training: Epoch {:04d} | Total Time {:.1f}s'.format(epoch, time() - time0))\n","    return model, data, Ks, device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["print(f\"\\nComputing {'KGAT'} algorithm on Movielens {'100k'}\")\n","model, data, Ks, device, time_train = train_kgat()\n","print('time_train: ', time_train)\n","_, metrics_dict_kgat = evaluate_kgat(model, data, Ks, device)\n","print(metrics_dict_kgat)"]},{"cell_type":"markdown","metadata":{"id":"QsJmgwgNsBE8"},"source":["## LightGCN"]},{"cell_type":"markdown","metadata":{},"source":["### Tuning alpha_ks(old)"]},{"cell_type":"code","execution_count":4,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":[">>SEED: 2020\n","\u001b[0;30;43mloading [LightGCN/data/amazon-book]\u001b[0m\n"]},{"ename":"ValueError","evalue":"invalid literal for int() with base 10: ''","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8908/2404563006.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mLightGCN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_lgcn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_lightgcn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# input 0: original layer-stacking weights, 1: modified layer-stacking weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrun_lightgcn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\LightGCN\\code\\main_lgcn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\">>SEED:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# ==============================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mLightGCN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mregister\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mLightGCN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\LightGCN\\code\\register.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'gowalla'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yelp2018'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'amazon-book'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'movielens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LightGCN/data/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lastfm'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLastFM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\LightGCN\\code\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, path)\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                     \u001b[0muid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                     \u001b[0mtestUniqueUsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\4222project\\LightGCN\\code\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                     \u001b[0muid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                     \u001b[0mtestUniqueUsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"]}],"source":["from LightGCN.code.main_lgcn import run_lightgcn\n","# input 0: original layer-stacking weights, 1: modified layer-stacking weights\n","run_lightgcn(0)"]},{"cell_type":"code","execution_count":1,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[ 0.1383],\n","        [-0.4727],\n","        [-0.5280],\n","        [-0.4990]], requires_grad=True)\n","\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",">>SEED: 2020\n","\u001b[0;30;43mloading [LightGCN/data/movielens]\u001b[0m\n","44140 interactions for training\n","11235 interactions for testing\n","movielens Sparsity : 0.03502087022514546\n","movielens is ready to go\n","===========config================\n","{'A_n_fold': 100,\n"," 'A_split': False,\n"," 'alphas': Parameter containing:\n","tensor([[ 0.1383],\n","        [-0.4727],\n","        [-0.5280],\n","        [-0.4990]], requires_grad=True),\n"," 'bigdata': False,\n"," 'bpr_batch_size': 2048,\n"," 'decay': 0.0001,\n"," 'dropout': 0,\n"," 'keep_prob': 0.6,\n"," 'latent_dim_rec': 64,\n"," 'lightGCN_n_layers': 3,\n"," 'lr': 0.0001,\n"," 'multicore': 0,\n"," 'pretrain': 0,\n"," 'stacking_func': 1,\n"," 'test_u_batch_size': 45}\n","cores for test: 6\n","comment: lgn\n","tensorboard: 1\n","LOAD: 0\n","Weight path: ./checkpoints\n","Test Topks: [20, 40, 60]\n","using bpr loss\n","===========end===================\n","\u001b[0;30;43mstacking_func: 1\u001b[0m\n","\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n","loading adjacency matrix\n","successfully loaded...\n","don't split the matrix\n","lgn is already to go(dropout:0)\n","load and save to /Users/sheng/Documents/GitHub/4222project/LightGCN\\code\\checkpoints\\lgn-movielens-3-64.pth.tar\n","\u001b[0;30;43m[TEST]\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\sheng\\anaconda3\\lib\\site-packages\\sympy\\core\\relational.py:495: SymPyDeprecationWarning: \n","\n","Eq(expr) with rhs default to 0 has been deprecated since SymPy 1.5.\n","Use Eq(expr, 0) instead. See\n","https://github.com/sympy/sympy/issues/16587 for more info.\n","\n","  SymPyDeprecationWarning(\n"]},{"name":"stdout","output_type":"stream","text":["{'precision': array([0.01589912, 0.01600877, 0.01622807]), 'recall': array([0.01462073, 0.03054276, 0.04603931]), 'ndcg': array([0.01892505, 0.02382464, 0.02942618])}\n","EPOCH[1/100] loss0.672-|Sample:0.63|\n","EPOCH[2/100] loss0.669-|Sample:0.85|\n","EPOCH[3/100] loss0.666-|Sample:0.72|\n","EPOCH[4/100] loss0.662-|Sample:0.47|\n","EPOCH[5/100] loss0.656-|Sample:0.49|\n","EPOCH[6/100] loss0.649-|Sample:0.42|\n","EPOCH[7/100] loss0.640-|Sample:0.50|\n","EPOCH[8/100] loss0.629-|Sample:0.44|\n","EPOCH[9/100] loss0.616-|Sample:0.53|\n","EPOCH[10/100] loss0.600-|Sample:0.47|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.12280702, 0.10219298, 0.09137427]), 'recall': array([0.10925876, 0.18262312, 0.23541308]), 'ndcg': array([0.15849368, 0.16927693, 0.18434168])}\n","EPOCH[11/100] loss0.583-|Sample:0.54|\n","EPOCH[12/100] loss0.562-|Sample:0.43|\n","EPOCH[13/100] loss0.541-|Sample:0.57|\n","EPOCH[14/100] loss0.520-|Sample:0.44|\n","EPOCH[15/100] loss0.496-|Sample:0.52|\n","EPOCH[16/100] loss0.473-|Sample:0.45|\n","EPOCH[17/100] loss0.451-|Sample:0.56|\n","EPOCH[18/100] loss0.428-|Sample:0.49|\n","EPOCH[19/100] loss0.410-|Sample:0.61|\n","EPOCH[20/100] loss0.394-|Sample:0.51|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.1691886 , 0.14205044, 0.12459795]), 'recall': array([0.18439754, 0.28255814, 0.3586277 ]), 'ndcg': array([0.2377322 , 0.25658515, 0.27889685])}\n","EPOCH[21/100] loss0.380-|Sample:0.51|\n","EPOCH[22/100] loss0.364-|Sample:0.43|\n","EPOCH[23/100] loss0.351-|Sample:0.49|\n","EPOCH[24/100] loss0.338-|Sample:0.49|\n","EPOCH[25/100] loss0.331-|Sample:0.42|\n","EPOCH[26/100] loss0.320-|Sample:0.50|\n","EPOCH[27/100] loss0.313-|Sample:0.42|\n","EPOCH[28/100] loss0.306-|Sample:0.49|\n","EPOCH[29/100] loss0.303-|Sample:0.44|\n","EPOCH[30/100] loss0.294-|Sample:0.49|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.17127193, 0.14309211, 0.12664474]), 'recall': array([0.19278946, 0.29134749, 0.37457021]), 'ndcg': array([0.2429181 , 0.26250875, 0.28758433])}\n","EPOCH[31/100] loss0.288-|Sample:0.49|\n","EPOCH[32/100] loss0.285-|Sample:0.58|\n","EPOCH[33/100] loss0.281-|Sample:0.49|\n","EPOCH[34/100] loss0.279-|Sample:0.48|\n","EPOCH[35/100] loss0.276-|Sample:0.42|\n","EPOCH[36/100] loss0.276-|Sample:0.58|\n","EPOCH[37/100] loss0.272-|Sample:0.45|\n","EPOCH[38/100] loss0.263-|Sample:0.50|\n","EPOCH[39/100] loss0.264-|Sample:0.41|\n","EPOCH[40/100] loss0.264-|Sample:0.49|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.17576754, 0.14588816, 0.12792398]), 'recall': array([0.20396208, 0.30346565, 0.3869858 ]), 'ndcg': array([0.25208181, 0.27205509, 0.29685795])}\n","EPOCH[41/100] loss0.260-|Sample:0.42|\n","EPOCH[42/100] loss0.258-|Sample:0.52|\n","EPOCH[43/100] loss0.255-|Sample:0.42|\n","EPOCH[44/100] loss0.253-|Sample:0.42|\n","EPOCH[45/100] loss0.255-|Sample:0.52|\n","EPOCH[46/100] loss0.254-|Sample:0.42|\n","EPOCH[47/100] loss0.250-|Sample:0.50|\n","EPOCH[48/100] loss0.252-|Sample:0.50|\n","EPOCH[49/100] loss0.249-|Sample:0.48|\n","EPOCH[50/100] loss0.248-|Sample:0.42|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.17971491, 0.14989035, 0.13077485]), 'recall': array([0.21125569, 0.32015462, 0.40302141]), 'ndcg': array([0.26166891, 0.28456611, 0.30900501])}\n","EPOCH[51/100] loss0.242-|Sample:0.49|\n","EPOCH[52/100] loss0.242-|Sample:0.41|\n","EPOCH[53/100] loss0.244-|Sample:0.50|\n","EPOCH[54/100] loss0.240-|Sample:0.41|\n","EPOCH[55/100] loss0.240-|Sample:0.49|\n","EPOCH[56/100] loss0.237-|Sample:0.42|\n","EPOCH[57/100] loss0.237-|Sample:0.41|\n","EPOCH[58/100] loss0.233-|Sample:0.48|\n","EPOCH[59/100] loss0.235-|Sample:0.43|\n","EPOCH[60/100] loss0.229-|Sample:0.53|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.18662281, 0.15350877, 0.13450292]), 'recall': array([0.22158973, 0.33277912, 0.41602633]), 'ndcg': array([0.27141654, 0.29364496, 0.31868881])}\n","EPOCH[61/100] loss0.233-|Sample:0.49|\n","EPOCH[62/100] loss0.230-|Sample:0.50|\n","EPOCH[63/100] loss0.228-|Sample:0.50|\n","EPOCH[64/100] loss0.232-|Sample:0.52|\n","EPOCH[65/100] loss0.228-|Sample:0.43|\n","EPOCH[66/100] loss0.224-|Sample:0.53|\n","EPOCH[67/100] loss0.227-|Sample:0.45|\n","EPOCH[68/100] loss0.219-|Sample:0.42|\n","EPOCH[69/100] loss0.218-|Sample:0.56|\n","EPOCH[70/100] loss0.219-|Sample:0.45|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.19232456, 0.15822368, 0.13819444]), 'recall': array([0.2272747 , 0.34449762, 0.42820812]), 'ndcg': array([0.27905355, 0.30261549, 0.32753749])}\n","EPOCH[71/100] loss0.219-|Sample:0.58|\n","EPOCH[72/100] loss0.219-|Sample:0.44|\n","EPOCH[73/100] loss0.217-|Sample:0.70|\n","EPOCH[74/100] loss0.217-|Sample:0.65|\n","EPOCH[75/100] loss0.214-|Sample:0.54|\n","EPOCH[76/100] loss0.213-|Sample:0.44|\n","EPOCH[77/100] loss0.212-|Sample:0.43|\n","EPOCH[78/100] loss0.213-|Sample:0.50|\n","EPOCH[79/100] loss0.210-|Sample:0.43|\n","EPOCH[80/100] loss0.212-|Sample:0.50|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.2002193 , 0.16288377, 0.14214181]), 'recall': array([0.23541145, 0.35620946, 0.44097239]), 'ndcg': array([0.28825583, 0.31118909, 0.33638911])}\n","EPOCH[81/100] loss0.211-|Sample:0.44|\n","EPOCH[82/100] loss0.207-|Sample:0.65|\n","EPOCH[83/100] loss0.206-|Sample:0.47|\n","EPOCH[84/100] loss0.211-|Sample:0.58|\n","EPOCH[85/100] loss0.203-|Sample:0.44|\n","EPOCH[86/100] loss0.203-|Sample:0.55|\n","EPOCH[87/100] loss0.204-|Sample:0.46|\n","EPOCH[88/100] loss0.202-|Sample:0.51|\n","EPOCH[89/100] loss0.201-|Sample:0.64|\n","EPOCH[90/100] loss0.201-|Sample:0.58|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.20745614, 0.16677632, 0.14612573]), 'recall': array([0.24335206, 0.361915  , 0.45425934]), 'ndcg': array([0.29648179, 0.31745574, 0.34505775])}\n","EPOCH[91/100] loss0.203-|Sample:0.50|\n","EPOCH[92/100] loss0.203-|Sample:0.43|\n","EPOCH[93/100] loss0.196-|Sample:0.49|\n","EPOCH[94/100] loss0.197-|Sample:0.40|\n","EPOCH[95/100] loss0.194-|Sample:0.48|\n","EPOCH[96/100] loss0.199-|Sample:0.41|\n","EPOCH[97/100] loss0.196-|Sample:0.50|\n","EPOCH[98/100] loss0.199-|Sample:0.45|\n","EPOCH[99/100] loss0.192-|Sample:0.48|\n","EPOCH[100/100] loss0.193-|Sample:0.41|\n"]}],"source":["from LightGCN.code.main_lgcn import run_lightgcn\n","run_lightgcn(1)"]},{"cell_type":"code","execution_count":2,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0;30;43mstacking_func: 1.5\u001b[0m\n","\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n","loading adjacency matrix\n","lgn is already to go(dropout:0)\n","load and save to /Users/sheng/Documents/GitHub/4222project/LightGCN\\code\\checkpoints\\lgn-movielens-3-64.pth.tar\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.01765351, 0.01699561, 0.01736111]), 'recall': array([0.01354759, 0.02529469, 0.03854851]), 'ndcg': array([0.02188969, 0.02450799, 0.02936119])}\n","EPOCH[1/100] loss0.692-|Sample:0.51|\n","EPOCH[2/100] loss0.692-|Sample:1.06|\n","EPOCH[3/100] loss0.691-|Sample:0.70|\n","EPOCH[4/100] loss0.691-|Sample:0.50|\n","EPOCH[5/100] loss0.691-|Sample:0.56|\n","EPOCH[6/100] loss0.691-|Sample:0.40|\n","EPOCH[7/100] loss0.690-|Sample:0.41|\n","EPOCH[8/100] loss0.689-|Sample:0.50|\n","EPOCH[9/100] loss0.689-|Sample:0.41|\n","EPOCH[10/100] loss0.688-|Sample:0.49|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.1129386 , 0.09517544, 0.08490497]), 'recall': array([0.1011459 , 0.16026948, 0.21249241]), 'ndcg': array([0.14638553, 0.15399579, 0.16839209])}\n","EPOCH[11/100] loss0.686-|Sample:0.41|\n","EPOCH[12/100] loss0.685-|Sample:0.48|\n","EPOCH[13/100] loss0.683-|Sample:0.42|\n","EPOCH[14/100] loss0.681-|Sample:0.49|\n","EPOCH[15/100] loss0.678-|Sample:0.41|\n","EPOCH[16/100] loss0.675-|Sample:0.50|\n","EPOCH[17/100] loss0.672-|Sample:0.43|\n","EPOCH[18/100] loss0.668-|Sample:0.48|\n","EPOCH[19/100] loss0.664-|Sample:0.51|\n","EPOCH[20/100] loss0.659-|Sample:0.47|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.16907895, 0.14385965, 0.12788743]), 'recall': array([0.19032264, 0.284972  , 0.35744378]), 'ndcg': array([0.23827638, 0.25786575, 0.28053935])}\n","EPOCH[21/100] loss0.654-|Sample:0.42|\n","EPOCH[22/100] loss0.648-|Sample:0.50|\n","EPOCH[23/100] loss0.642-|Sample:0.43|\n","EPOCH[24/100] loss0.636-|Sample:0.43|\n","EPOCH[25/100] loss0.630-|Sample:0.54|\n","EPOCH[26/100] loss0.623-|Sample:0.47|\n","EPOCH[27/100] loss0.616-|Sample:0.49|\n","EPOCH[28/100] loss0.609-|Sample:0.43|\n","EPOCH[29/100] loss0.602-|Sample:0.49|\n","EPOCH[30/100] loss0.593-|Sample:0.42|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.17028509, 0.14446272, 0.12770468]), 'recall': array([0.18814045, 0.283431  , 0.35666347]), 'ndcg': array([0.23817627, 0.25797701, 0.28042328])}\n","EPOCH[31/100] loss0.586-|Sample:0.51|\n","EPOCH[32/100] loss0.579-|Sample:0.44|\n","EPOCH[33/100] loss0.570-|Sample:0.56|\n","EPOCH[34/100] loss0.562-|Sample:0.52|\n","EPOCH[35/100] loss0.555-|Sample:0.51|\n","EPOCH[36/100] loss0.545-|Sample:0.50|\n","EPOCH[37/100] loss0.537-|Sample:0.46|\n","EPOCH[38/100] loss0.529-|Sample:0.49|\n","EPOCH[39/100] loss0.522-|Sample:0.46|\n","EPOCH[40/100] loss0.515-|Sample:0.55|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.16962719, 0.14281798, 0.12660819]), 'recall': array([0.18412366, 0.28147345, 0.35484466]), 'ndcg': array([0.2371579 , 0.25681111, 0.27946188])}\n","EPOCH[41/100] loss0.508-|Sample:0.42|\n","EPOCH[42/100] loss0.499-|Sample:0.49|\n","EPOCH[43/100] loss0.493-|Sample:0.44|\n","EPOCH[44/100] loss0.486-|Sample:0.50|\n","EPOCH[45/100] loss0.478-|Sample:0.44|\n","EPOCH[46/100] loss0.470-|Sample:0.49|\n","EPOCH[47/100] loss0.465-|Sample:0.44|\n","EPOCH[48/100] loss0.459-|Sample:0.41|\n","EPOCH[49/100] loss0.451-|Sample:0.51|\n","EPOCH[50/100] loss0.446-|Sample:0.42|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.16875   , 0.14199561, 0.12602339]), 'recall': array([0.18271088, 0.28092236, 0.35546883]), 'ndcg': array([0.23561988, 0.25571028, 0.27876197])}\n","EPOCH[51/100] loss0.441-|Sample:0.48|\n","EPOCH[52/100] loss0.434-|Sample:0.42|\n","EPOCH[53/100] loss0.428-|Sample:0.48|\n","EPOCH[54/100] loss0.423-|Sample:0.41|\n","EPOCH[55/100] loss0.417-|Sample:0.50|\n","EPOCH[56/100] loss0.412-|Sample:0.41|\n","EPOCH[57/100] loss0.409-|Sample:0.43|\n","EPOCH[58/100] loss0.403-|Sample:0.41|\n","EPOCH[59/100] loss0.399-|Sample:0.41|\n","EPOCH[60/100] loss0.393-|Sample:0.49|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.16885965, 0.14122807, 0.12584064]), 'recall': array([0.18384988, 0.28109942, 0.3560518 ]), 'ndcg': array([0.23507522, 0.25466712, 0.27816201])}\n","EPOCH[61/100] loss0.393-|Sample:0.44|\n","EPOCH[62/100] loss0.386-|Sample:0.47|\n","EPOCH[63/100] loss0.382-|Sample:0.40|\n","EPOCH[64/100] loss0.376-|Sample:0.48|\n","EPOCH[65/100] loss0.373-|Sample:0.40|\n","EPOCH[66/100] loss0.370-|Sample:0.46|\n","EPOCH[67/100] loss0.368-|Sample:0.41|\n","EPOCH[68/100] loss0.364-|Sample:0.47|\n","EPOCH[69/100] loss0.359-|Sample:0.40|\n","EPOCH[70/100] loss0.359-|Sample:0.52|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.1683114 , 0.14073465, 0.12576754]), 'recall': array([0.18393194, 0.28109179, 0.35710499]), 'ndcg': array([0.23454778, 0.25441108, 0.27840195])}\n","EPOCH[71/100] loss0.354-|Sample:0.42|\n","EPOCH[72/100] loss0.352-|Sample:0.48|\n","EPOCH[73/100] loss0.348-|Sample:0.42|\n","EPOCH[74/100] loss0.344-|Sample:0.50|\n","EPOCH[75/100] loss0.344-|Sample:0.43|\n","EPOCH[76/100] loss0.341-|Sample:0.43|\n","EPOCH[77/100] loss0.339-|Sample:0.59|\n","EPOCH[78/100] loss0.334-|Sample:0.41|\n","EPOCH[79/100] loss0.334-|Sample:0.51|\n","EPOCH[80/100] loss0.332-|Sample:0.42|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.1685307 , 0.140625  , 0.12565789]), 'recall': array([0.18376917, 0.28174677, 0.35858376]), 'ndcg': array([0.23365432, 0.25395779, 0.27832075])}\n","EPOCH[81/100] loss0.331-|Sample:0.50|\n","EPOCH[82/100] loss0.324-|Sample:0.42|\n","EPOCH[83/100] loss0.325-|Sample:0.50|\n","EPOCH[84/100] loss0.323-|Sample:0.42|\n","EPOCH[85/100] loss0.322-|Sample:0.59|\n","EPOCH[86/100] loss0.319-|Sample:0.42|\n","EPOCH[87/100] loss0.319-|Sample:0.49|\n","EPOCH[88/100] loss0.314-|Sample:0.42|\n","EPOCH[89/100] loss0.315-|Sample:0.41|\n","EPOCH[90/100] loss0.314-|Sample:0.50|\n","\u001b[0;30;43m[TEST]\u001b[0m\n","{'precision': array([0.16885965, 0.14024123, 0.1251462 ]), 'recall': array([0.1854347 , 0.28497162, 0.35847598]), 'ndcg': array([0.23433557, 0.25466082, 0.27836778])}\n","EPOCH[91/100] loss0.311-|Sample:0.41|\n","EPOCH[92/100] loss0.308-|Sample:0.51|\n","EPOCH[93/100] loss0.304-|Sample:0.43|\n","EPOCH[94/100] loss0.307-|Sample:0.53|\n","EPOCH[95/100] loss0.304-|Sample:0.43|\n","EPOCH[96/100] loss0.303-|Sample:0.48|\n","EPOCH[97/100] loss0.303-|Sample:0.42|\n","EPOCH[98/100] loss0.303-|Sample:0.49|\n","EPOCH[99/100] loss0.301-|Sample:0.42|\n","EPOCH[100/100] loss0.300-|Sample:0.50|\n"]}],"source":["from LightGCN.code.main_lgcn import run_lightgcn\n","run_lightgcn(1.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["from LightGCN.code.main_lgcn import run_lightgcn\n","run_lightgcn(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["from LightGCN.code.main_lgcn import run_lightgcn\n","run_lightgcn(3)"]},{"cell_type":"markdown","metadata":{},"source":["### For comparison"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1667642261028,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"BZtl_jr3sA1o","vscode":{"languageId":"python"}},"outputs":[],"source":["from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n","from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n","\n","def prepare_training_lightgcn(train, test):\n","    return ImplicitCF(train=train, test=test)\n","\n","def train_lightgcn(params, data):\n","    hparams = prepare_hparams(**params)\n","    model = LightGCN(hparams, data)\n","    with Timer() as t:\n","        model.fit()\n","    return model, t\n","\n","def recommend_k_lightgcn(model, test, train, top_k=DEFAULT_K, remove_seen=True):\n","    with Timer() as t:\n","        topk_scores = model.recommend_k_items(\n","            test, top_k=top_k, remove_seen=remove_seen\n","        )\n","    return topk_scores, t\n","\n","lightgcn_param = {\n","    \"yaml_file\": os.path.join(\"drive\", \"MyDrive\", \"4222Group9\", \"lightgcn.yaml\"),\n","    \"n_layers\": 3,\n","    \"batch_size\": 1024,\n","    \"epochs\": 10,\n","    \"learning_rate\": 0.005,\n","    \"eval_epoch\": 10,\n","    \"top_k\": DEFAULT_K,\n","}"]},{"cell_type":"markdown","metadata":{"id":"W8cmNmNcsIrU"},"source":["## Comparison"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1667642261029,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"WDnMUwTkmaVl","vscode":{"languageId":"python"}},"outputs":[],"source":["params = {\n","    \"als\": als_params,\n","    \"ncf\": ncf_params,\n","    \"lightgcn\": lightgcn_param,\n","}\n","prepare_training_data = {\n","    \"als\": prepare_training_als,\n","    \"ncf\": prepare_training_ncf,\n","    \"lightgcn\": prepare_training_lightgcn,\n","}\n","\n","\n","from recommenders.evaluation.spark_evaluation import (\n","    SparkRatingEvaluation,\n","    SparkRankingEvaluation,\n",")\n","def rating_metrics_pyspark(test, predictions):\n","    rating_eval = SparkRatingEvaluation(test, predictions, **COL_DICT)\n","    return {\n","        \"RMSE\": rating_eval.rmse(),\n","        \"MAE\": rating_eval.mae(),\n","        \"R2\": rating_eval.exp_var(),\n","        \"Explained Variance\": rating_eval.rsquared(),\n","    }\n","def ranking_metrics_pyspark(test, predictions, k=DEFAULT_K):\n","    rank_eval = SparkRankingEvaluation(\n","        test, predictions, k=k, relevancy_method=\"top_k\", **COL_DICT\n","    )\n","    return {\n","        \"MAP\": rank_eval.map_at_k(),\n","        \"nDCG@k\": rank_eval.ndcg_at_k(),\n","        \"Precision@k\": rank_eval.precision_at_k(),\n","        \"Recall@k\": rank_eval.recall_at_k(),\n","    }\n","\n","prepare_metrics_data = {\n","    \"als\": lambda train, test: prepare_metrics_als(train, test),\n","}\n","trainer = {\n","    \"als\": lambda params, data: train_als(params, data),\n","    \"ncf\": lambda params, data: train_ncf(params, data),\n","    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n","}\n","rating_predictor = {\n","    \"als\": lambda model, test: predict_als(model, test),\n","}\n","rating_evaluator = {\n","    \"als\": lambda test, predictions: rating_metrics_pyspark(test, predictions)\n","}\n","ranking_predictor = {\n","    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n","    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n","    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n","}\n","ranking_evaluator = {\n","    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n","    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n","    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n","}\n","metrics = {\n","    \"als\": [\"rating\", \"ranking\"],\n","    \"ncf\": [\"ranking\"],\n","    \"lightgcn\": [\"ranking\"]\n","}"]},{"cell_type":"markdown","metadata":{"id":"3B4ScYiXzCN1"},"source":["# 5 Hyperparameter Tunning"]},{"cell_type":"code","execution_count":18,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["def generate_summary(data, algo, k, train_time, time_rating, rating_metrics, time_ranking, ranking_metrics):\n","    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": time_rating, \"Recommending time (s)\": time_ranking}\n","    if rating_metrics is None:\n","        rating_metrics = {\n","            \"RMSE\": np.nan,\n","            \"MAE\": np.nan,\n","            \"R2\": np.nan,\n","            \"Explained Variance\": np.nan,\n","        }\n","    if ranking_metrics is None:\n","        ranking_metrics = {\n","            \"MAP\": np.nan,\n","            \"nDCG@k\": np.nan,\n","            \"Precision@k\": np.nan,\n","            \"Recall@k\": np.nan,\n","        }\n","    summary.update(rating_metrics)\n","    summary.update(ranking_metrics)\n","    return summary"]},{"cell_type":"code","execution_count":19,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["data_sizes = [\"100k\"] # Movielens data size: 100k, 1m, 10m, or 20m\n","algorithms = [ \"lightgcn\"]"]},{"cell_type":"markdown","metadata":{},"source":["## Sanity Check by Overfitting on Small Data (skip)"]},{"cell_type":"code","execution_count":20,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pytorch_lightning'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!pip install pytorch-lightning\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, seed_everything\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLightGCN\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain_lgcn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanity_check\n\u001b[1;32m      5\u001b[0m seed_everything(\u001b[38;5;241m42\u001b[39m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"]}],"source":["#!pip install pytorch-lightning\n","from pytorch_lightning import Trainer, seed_everything\n","from LightGCN.code.main_lgcn import sanity_check\n","\n","seed_everything(42, workers=True)\n","\n","model = sanity_check()\n","trainer = Trainer(max_epochs=10000, overfit_batches=0.01)\n","trainer.fit(model)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":22,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../../../ml-100k/u.data'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m<timed exec>:10\u001b[0m\n","File \u001b[0;32m/data/yzhanglo/4222project/recommenders/datasets/movielens.py:255\u001b[0m, in \u001b[0;36mload_pandas_df\u001b[0;34m(size, header, local_cache_path, title_col, genres_col, year_col)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39msize = size.lower()\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39mif size not in DATA_FORMAT and size not in MOCK_DATA_FORMAT:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39m        df = df.merge(item_df, on=header[1])\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m size\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m100k\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 255\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../../../ml-100k/u.data\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m df\n","File \u001b[0;32m/data/yzhanglo/miniconda/envs/cu101/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m/data/yzhanglo/miniconda/envs/cu101/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[0;32m/data/yzhanglo/miniconda/envs/cu101/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[0;32m/data/yzhanglo/miniconda/envs/cu101/lib/python3.8/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[0;32m/data/yzhanglo/miniconda/envs/cu101/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m     f,\n\u001b[1;32m   1218\u001b[0m     mode,\n\u001b[1;32m   1219\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1220\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1223\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1224\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1225\u001b[0m )\n\u001b[1;32m   1226\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[0;32m/data/yzhanglo/miniconda/envs/cu101/lib/python3.8/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../ml-100k/u.data'"]}],"source":["%%time\n","\n","data_sizes = [\"100k\"] # Movielens data size: 100k, 1m, 10m, or 20m\n","algorithms = [ \"lightgcn\"]\n","\n","# For each data size and each algorithm, a recommender is evaluated. \n","cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n","df_results = pd.DataFrame(columns=cols)\n","\n","for data_size in data_sizes:\n","    # Load the dataset\n","    df = movielens.load_pandas_df(\n","        size=data_size,\n","        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n","    )\n","    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n","    \n","    # Split the dataset\n","    df_train, df_test = python_stratified_split(df,\n","                                                ratio=0.75, \n","                                                min_rating=1, \n","                                                filter_by=\"item\", \n","                                                col_user=DEFAULT_USER_COL, \n","                                                col_item=DEFAULT_ITEM_COL\n","                                                )\n","   \n","    # Loop through the algos\n","    for algo in algorithms:\n","        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n","        if algo == 'kgat':\n","            model, data, Ks, device, time_train = train_kgat()\n","            _, metrics_dict_kgat = evaluate_kgat(model, data, Ks, device)\n","            print(metrics_dict_kgat)\n","            # Record results\n","            #summary = generate_summary('100k', algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            #df_results.loc[df_results.shape[0] + 1] = summary\n","            \n","        else:\n","            # Data prep for training set\n","            train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            \n","            # Get model parameters\n","            model_params = params[algo]\n","            \n","            # Train the model\n","            model, time_train = trainer[algo](model_params, train)\n","            print(f\"Training time: {time_train}s\")\n","                    \n","            # Predict and evaluate\n","            train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            \n","            if \"rating\" in metrics[algo]:   \n","                # Predict for rating\n","                preds, time_rating = rating_predictor[algo](model, test)\n","                print(f\"Rating prediction time: {time_rating}s\")\n","                \n","                # Evaluate for rating\n","                ratings = rating_evaluator[algo](test, preds)\n","            else:\n","                ratings = None\n","                time_rating = np.nan\n","            \n","            if \"ranking\" in metrics[algo]:\n","                # Predict for ranking\n","                top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n","                print(f\"Ranking prediction time: {time_ranking}s\")\n","                \n","                # Evaluate for rating\n","                rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n","            else:\n","                rankings = None\n","                time_ranking = np.nan\n","                \n","            # Record results\n","            summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            df_results.loc[df_results.shape[0] + 1] = summary\n","        \n","print(\"\\nComputation finished\")"]},{"cell_type":"markdown","metadata":{},"source":["## Training Plot"]},{"cell_type":"markdown","metadata":{},"source":["click \"launch TensorBoard Session\" in main_lgcn.py"]},{"cell_type":"markdown","metadata":{},"source":["# 6 Comparisons on Movielens and Movie"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1667642261031,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"8reKYmEH2d-k","vscode":{"languageId":"python"}},"outputs":[],"source":["data_sizes = [\"100k\",\"1m\"] # Movielens data size: 100k, 1m, 10m, or 20m\n","#algorithms = [ \"lightgcn\"]\n","algorithms = [\"als\", \"ncf\", \"lightgcn\", \"kgat\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1667642261031,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"-17fyWdVmiHM","vscode":{"languageId":"python"}},"outputs":[],"source":["%%time\n","\n","# For each data size and each algorithm, a recommender is evaluated. \n","cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n","df_results = pd.DataFrame(columns=cols)\n","\n","for data_size in data_sizes:\n","    # Load the dataset\n","    df = movielens.load_pandas_df(\n","        size=data_size,\n","        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n","    )\n","    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n","    \n","    # Split the dataset\n","    df_train, df_test = python_stratified_split(df,\n","                                                ratio=0.75, \n","                                                min_rating=1, \n","                                                filter_by=\"item\", \n","                                                col_user=DEFAULT_USER_COL, \n","                                                col_item=DEFAULT_ITEM_COL\n","                                                )\n","   \n","    # Loop through the algos\n","    for algo in algorithms:\n","        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n","        if algo == 'kgat':\n","            model, data, Ks, device, time_train = train_kgat()\n","            _, metrics_dict_kgat = evaluate_kgat(model, data, Ks, device)\n","            print(metrics_dict_kgat)\n","            # Record results\n","            #summary = generate_summary('100k', algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            #df_results.loc[df_results.shape[0] + 1] = summary\n","            \n","        else:\n","            # Data prep for training set\n","            train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            \n","            # Get model parameters\n","            model_params = params[algo]\n","            \n","            # Train the model\n","            model, time_train = trainer[algo](model_params, train)\n","            print(f\"Training time: {time_train}s\")\n","                    \n","            # Predict and evaluate\n","            train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n","            \n","            if \"rating\" in metrics[algo]:   \n","                # Predict for rating\n","                preds, time_rating = rating_predictor[algo](model, test)\n","                print(f\"Rating prediction time: {time_rating}s\")\n","                \n","                # Evaluate for rating\n","                ratings = rating_evaluator[algo](test, preds)\n","            else:\n","                ratings = None\n","                time_rating = np.nan\n","            \n","            if \"ranking\" in metrics[algo]:\n","                # Predict for ranking\n","                top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n","                print(f\"Ranking prediction time: {time_ranking}s\")\n","                \n","                # Evaluate for rating\n","                rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n","            else:\n","                rankings = None\n","                time_ranking = np.nan\n","                \n","            # Record results\n","            summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n","            df_results.loc[df_results.shape[0] + 1] = summary\n","        \n","print(\"\\nComputation finished\")"]},{"cell_type":"markdown","metadata":{},"source":["## Print the result summary"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1667642261031,"user":{"displayName":"Yj WEI","userId":"09205277183220707996"},"user_tz":-480},"id":"36QRfkqVrYzi","vscode":{"languageId":"python"}},"outputs":[],"source":["df_results"]},{"cell_type":"markdown","metadata":{"id":"seUWygXTzYfc"},"source":["# 7 Credit and Reference\n","\n","1. https://github.com/microsoft/recommenders"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python [conda env:cu101]","language":"python","name":"conda-env-cu101-py"},"vscode":{"interpreter":{"hash":"8006cd3f4b5a31b91c77e5b5a521798c8412e8b93831dc7973f670e0263ddfcb"}}},"nbformat":4,"nbformat_minor":0}
